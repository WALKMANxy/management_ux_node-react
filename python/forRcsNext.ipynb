{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#FIX CLIENTS#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import json\n",
    "\n",
    "# Define the input and output file paths\n",
    "xls_file = \"Z:/My Drive/rcs/Estrapolo clienti con dettagli per Damiano.xls\"\n",
    "json_output_file = \"D:/coding/rcs_management_project-1/frontend/public/data/clientdetailsdataset02072024.min.json\"\n",
    "\n",
    "# List of foreign \"RAGIONE SOCIALE\"\n",
    "foreign_ragione_sociale = [\n",
    "    \"KOSSER JSC\",\n",
    "    \"PRESTOLITE ELECTIRC LIMITED\",\n",
    "    \"SHF TRADE TD LTD\",\n",
    "    \"NEAT AUTOS LTD\",\n",
    "    \"SUPERIORCARUSO SERVICE\",\n",
    "    \"MOTOR & TRANSMISSIONSTEKNIK\",\n",
    "    \"RAIN GROUP TRADING FZE\",\n",
    "    \"LUCAS DIESEL Inyeccion Diesel\",\n",
    "    \"SURIPE_x001a_S - IMPORTA_x001a_O E\",\n",
    "    \"AOI SOLUTIONS GMBH\",\n",
    "    \"MARIO SPITERI PARTS & SERVICE\",\n",
    "    \"HOLSTEIN-HANDEL\",\n",
    "    \"RAY CINI TRANS\",\n",
    "    \"GAMMA TECHNICAL CORPORATION\",\n",
    "    \"GOBITRADE LTD.\",\n",
    "    \"CARPARTS IMPORT EXPORT KFT\",\n",
    "    \"REMANTE GROUP S.R.O.\",\n",
    "    \"PURIC D.O.O.\",\n",
    "    \"FERDINAND BILSTEIN UK LTD\",\n",
    "    \"ATLANTIC SPARE PARTS\",\n",
    "    \"GEZAIRI CO. Attn: Mr. Halo\",\n",
    "    \"RECANPRI, S.L.\",\n",
    "    \"SPH - SPARE PARTS HOUSE LDA\",\n",
    "    \"DELPHI DIESEL AFTERMARKET\",\n",
    "    \"PRESTOLITE ELECTRIC LIMITED\",\n",
    "    \"AVESA S.L.\",\n",
    "    \"TECNODIESEL MURCIA S.L.\",\n",
    "    \"MERLIN DIESEL SYSTEMS LTD\",\n",
    "    \"MERLIN DIESEL SYSTEM LTD\",\n",
    "    \"AMAZON EU S.A.R.L.\",\n",
    "    \"JOHN'S DIESEL SERVICE'S SQAQ\",\n",
    "    \"S.C DIESEL SOF S.R.L. STR\",\n",
    "    \"ARROWTRONIC LTD-EMS\",\n",
    "    \"HORIZON PROCUREMENTS\",\n",
    "    \"SARL PROIETTI FARNESE\",\n",
    "    \"TYRONE DIESEL SYSTEMS\",\n",
    "    \"DIESELWELT BRENNER GMBH\",\n",
    "    \"TURBOTECNIC AUTOMOCIO S.L.\",\n",
    "    \"KUNSHAN POWER ASIA IMPORT &\",\n",
    "    \"ORION PART OTOM.IC VE DIS\",\n",
    "    \"GUANGZHOU BAISITE AUTO PARTS\",\n",
    "    \"IPT OTOMOTIV DIS TICARET\",\n",
    "    \"KONING TECHNISCH BEDRIJF B.V.\",\n",
    "    \"PORTLAOISE DIESEL INJECTION\",\n",
    "    \"CORCORANS ENGINEERING\",\n",
    "    \"ZHENGZHOU LISERON OIL PUMP &\",\n",
    "    \"LKV TEKNIK OTOMOTIV SANAYI IC\",\n",
    "    \"GUANGDONG TOPWAY TECH CO LTD\",\n",
    "    \"UNITED FUEL INJECTION\",\n",
    "    \"LA CASA DEL DIESEL S.L.\",\n",
    "    \"OTT-PUTIAN DIESEL SPARE PARTS\",\n",
    "    \"AUTORAK SP. Z.O.O.\",\n",
    "    \"IB TRADE\",\n",
    "    \"FLOTA SUARDIAZ S.L.U.\",\n",
    "    \"2T + M KFT\",\n",
    "    \"KENDIESEL\",\n",
    "    \"CASTY-ROMER S.L.\",\n",
    "    \"DIESELSERVICE STOKKING B.V.\",\n",
    "    \"SUPER ENGINEERING WORKS\",\n",
    "    \"DIJITAL PARCA PLATFORMU SATIS\",\n",
    "    \"GOODAPP\",\n",
    "    \"INJECCIO DIESEL JORDA, S.L\",\n",
    "    \"GUNEYBAGLILAR OTO YEDEK PAR.\",\n",
    "    \"D. HAUPT GMBH\",\n",
    "    \"ASIST OTO YEDEK PARCA SANAYI\",\n",
    "    \"UHURU MAX LIMITED\",\n",
    "    \"SYDNEY DIESEL CENTRE\",\n",
    "    \"TALLERES RUFRE S.L.\",\n",
    "    \"AB IMPORTS\",\n",
    "    \"FACEWORKS LIMITED\",\n",
    "    \"William Psaila\",\n",
    "    \"EURO PARTS TRUCKS & BUSES\",\n",
    "    \"PORTLAOISE DIESEL LTD\",\n",
    "    \"SUARDIAZ MANAGEMENT SERVICES\",\n",
    "    \"EAST HOI TRADING COMPANY FLAT\",\n",
    "    \"Karadaglar group otomotiv\",\n",
    "    \"KARCOM LTD\",\n",
    "    \"ERB ITALY SRL\",\n",
    "    \"A.F. BAEDER GES.M.B.H.\",\n",
    "    \"DIESEL INJECTOR REPAIR Ltd\",\n",
    "    \"FAHRENHEIT LOGISTICS LIMITED\",\n",
    "    \"S T EARTHMOVING SERVICES\",\n",
    "    \"GOLDFARB  and ASSOCIATES\",\n",
    "    \"PANDIESEL AEBE\",\n",
    "    \"ADF DIESEL\",\n",
    "    \"AutoDieselPart LLC\",\n",
    "    \"Goldfarb & Associates, Inc\",\n",
    "]\n",
    "\n",
    "\n",
    "# Function to clean and process each row from the XLS file and convert to JSON\n",
    "def process_xls_to_json(input_file, output_file):\n",
    "    wb = xlrd.open_workbook(input_file)\n",
    "    sheet = wb.sheet_by_index(0)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # Process each row starting from the second row (index 1)\n",
    "    for row_idx in range(1, sheet.nrows):\n",
    "        row = sheet.row_values(row_idx)\n",
    "\n",
    "        # Convert row values to strings\n",
    "        row = [str(val) for val in row]\n",
    "\n",
    "        # Remove leading zeros from CODICE (assuming it's the first column, adjust if necessary)\n",
    "        codice_cliente = row[0].lstrip(\"0\")\n",
    "        row[0] = codice_cliente\n",
    "\n",
    "        # Assign placeholder AG code 100 if missing or if AG code is 0 (assuming AG is the last column, adjust if necessary)\n",
    "        ag_code = row[-1]\n",
    "        if not ag_code.strip() or ag_code == \"0\":\n",
    "            row[-1] = \"100\"\n",
    "\n",
    "        # Check for foreign \"RAGIONE SOCIALE\" and assign AG 50\n",
    "        if row[1] in foreign_ragione_sociale:\n",
    "            row[-1] = \"50\"\n",
    "\n",
    "        # Check for \"RAGIONE SOCIALE\" exactly matching \"CLIENTE DA WEB\" and assign AG 60\n",
    "        if row[1].strip().upper() == \"CLIENTE DA WEB\":\n",
    "            row[-1] = \"60\"\n",
    "\n",
    "        # Append cleaned row to data list as a dictionary\n",
    "        data.append(dict(zip(sheet.row_values(0), row)))\n",
    "\n",
    "    # Write data to JSON file\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as jsonout:\n",
    "        json.dump(data, jsonout, separators=(\",\", \":\"), ensure_ascii=False)\n",
    "\n",
    "    print(\n",
    "        f\"XLS file {input_file} successfully processed. Cleaned data saved to {output_file}.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Process the XLS file\n",
    "process_xls_to_json(xls_file, json_output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#FIX AGENTS#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define the paths to the input and output files\n",
    "client_data_path = \"Z:/My Drive/rcs/business analyst/clientdetailsdataset02072024.min.json\"  # Path to the existing client data JSON file\n",
    "agent_data_path = \"Z:/My Drive/rcs/business analyst/agentDetailsYear2024-StatsSoFar-cleaned.min.json\"  # Path to the new agent data JSON file\n",
    "\n",
    "# Load client data\n",
    "with open(client_data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    clients = json.load(f)\n",
    "\n",
    "# Define a default dictionary to store agents and their clients\n",
    "agents_dict = defaultdict(\n",
    "    lambda: {\"id\": \"\", \"name\": \"\", \"email\": \"\", \"phone\": \"\", \"clients\": []}\n",
    ")\n",
    "\n",
    "# Define agent details (normally you would load this from a file or database)\n",
    "agent_details = [\n",
    "    {\"id\": \"10\", \"name\": \"Fazio Adriano Salvatore\"},\n",
    "    {\"id\": \"11\", \"name\": \"Salvatore Spinella\"},\n",
    "    {\"id\": \"12\", \"name\": \"Riccardo Carpentiere\"},\n",
    "    {\"id\": \"13\", \"name\": \"Vito D'Antonio\"},\n",
    "    {\"id\": \"14\", \"name\": \"G.C.\"},\n",
    "    {\"id\": \"15\", \"name\": \"Luddeni Renato\"},\n",
    "    {\"id\": \"16\", \"name\": \"Luca Scaffo\"},\n",
    "    {\"id\": \"50\", \"name\": \"Marco Coppola\"},\n",
    "    {\"id\": \"60\", \"name\": \"Web\"},\n",
    "    {\"id\": \"90\", \"name\": \"Direzionale\"},\n",
    "    {\"id\": \"91\", \"name\": \"Direzionale Diesel\"},\n",
    "    {\"id\": \"92\", \"name\": \"Direzionale D\"},\n",
    "    {\"id\": \"95\", \"name\": \"Cliente Agente\"},\n",
    "    {\"id\": \"99\", \"name\": \"Seguito da Avvocato\"},\n",
    "    {\"id\": \"100\", \"name\": \"Non Assegnato\"},\n",
    "]\n",
    "\n",
    "# Initialize the agents dictionary with agent details\n",
    "for agent in agent_details:\n",
    "    agents_dict[agent[\"id\"]][\"id\"] = agent[\"id\"]\n",
    "    agents_dict[agent[\"id\"]][\"name\"] = agent[\"name\"]\n",
    "\n",
    "# Assign clients to their respective agents\n",
    "for client in clients:\n",
    "    agent_id = client[\"AG\"]\n",
    "    agents_dict[agent_id][\"clients\"].append(client)\n",
    "\n",
    "# Convert the default dictionary to a list\n",
    "agents_list = list(agents_dict.values())\n",
    "\n",
    "# Write the output to a new JSON file\n",
    "with open(agent_data_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(agents_list, f, separators=(\",\", \":\"), ensure_ascii=False)\n",
    "\n",
    "print(\"Agent data with nested clients has been written to\", agent_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#FIX AGENTS N2#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent data with nested clients (CODICE and colour) has been written to Z:/My Drive/rcs/business analyst/agentdetailsdataset02072024.min.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "# Define the paths to the input and output files\n",
    "client_data_path = \"Z:/My Drive/rcs/rcsNext/data/clientdetailsdataset02072024.min.json\"  # Path to the existing client data JSON file\n",
    "agent_data_path = \"Z:/My Drive/rcs/business analyst/agentdetailsdataset02072024.min.json\"  # Path to the new agent data JSON file\n",
    "\n",
    "# Load client data\n",
    "with open(client_data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    clients = json.load(f)\n",
    "\n",
    "# Define a default dictionary to store agents and their clients\n",
    "agents_dict = defaultdict(\n",
    "    lambda: {\"id\": \"\", \"name\": \"\", \"email\": \"\", \"phone\": \"\", \"clients\": []}\n",
    ")\n",
    "\n",
    "\n",
    "# Function to generate a pastel color\n",
    "def generate_pastel_color():\n",
    "    hue = random.randint(0, 359)\n",
    "    saturation = 70 + random.randint(0, 19)  # Slightly higher saturation for pastel\n",
    "    lightness = 85 + random.randint(0, 9)  # High lightness for pastel\n",
    "    return f\"hsl({hue}, {saturation}%, {lightness}%)\"\n",
    "\n",
    "\n",
    "# Define agent details (normally you would load this from a file or database)\n",
    "agent_details = [\n",
    "    {\"id\": \"10\", \"name\": \"Fazio Adriano Salvatore\"},\n",
    "    {\"id\": \"11\", \"name\": \"Salvatore Spinella\"},\n",
    "    {\"id\": \"12\", \"name\": \"Riccardo Carpentiere\"},\n",
    "    {\"id\": \"13\", \"name\": \"Vito D'Antonio\"},\n",
    "    {\"id\": \"14\", \"name\": \"G.C.\"},\n",
    "    {\"id\": \"15\", \"name\": \"Luddeni Renato\"},\n",
    "    {\"id\": \"16\", \"name\": \"Luca Scaffo\"},\n",
    "    {\"id\": \"50\", \"name\": \"Marco Coppola\"},\n",
    "    {\"id\": \"60\", \"name\": \"Web\"},\n",
    "    {\"id\": \"90\", \"name\": \"Direzionale\"},\n",
    "    {\"id\": \"91\", \"name\": \"Direzionale Diesel\"},\n",
    "    {\"id\": \"92\", \"name\": \"Direzionale D\"},\n",
    "    {\"id\": \"95\", \"name\": \"Cliente Agente\"},\n",
    "    {\"id\": \"99\", \"name\": \"Seguito da Avvocato\"},\n",
    "    {\"id\": \"100\", \"name\": \"Non Assegnato\"},\n",
    "]\n",
    "\n",
    "# Initialize the agents dictionary with agent details\n",
    "for agent in agent_details:\n",
    "    agents_dict[agent[\"id\"]][\"id\"] = agent[\"id\"]\n",
    "    agents_dict[agent[\"id\"]][\"name\"] = agent[\"name\"]\n",
    "\n",
    "# Assign clients to their respective agents, only keeping the 'CODICE' field and adding a 'colour' field\n",
    "for client in clients:\n",
    "    agent_id = client[\"AG\"]\n",
    "    client_codice = {\"CODICE\": client[\"CODICE\"], \"colour\": generate_pastel_color()}\n",
    "    agents_dict[agent_id][\"clients\"].append(client_codice)\n",
    "\n",
    "# Convert the default dictionary to a list\n",
    "agents_list = list(agents_dict.values())\n",
    "\n",
    "# Write the output to a new JSON file\n",
    "with open(agent_data_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(agents_list, f, separators=(\",\", \":\"), ensure_ascii=False)\n",
    "\n",
    "print(\n",
    "    \"Agent data with nested clients (CODICE and colour) has been written to\",\n",
    "    agent_data_path,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CLEAN AND CONVERT MAIN DATASET#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Define the path pattern for the monthly CSV files\n",
    "file_pattern = (\n",
    "    \"Z:/My Drive/rcs/business analyst/Statistica_del_Venduto_e_Acquistato_2024_*.csv\"\n",
    ")\n",
    "file_paths = glob.glob(file_pattern)\n",
    "\n",
    "# Initialize lists to store dataframes\n",
    "df_list = []\n",
    "dropped_df_list = []\n",
    "\n",
    "# Define the foreign \"RAGIONE SOCIALE\" list\n",
    "foreign_ragione_sociale = [\n",
    "    \"KOSSER JSC\",\n",
    "    \"PRESTOLITE ELECTIRC LIMITED\",\n",
    "    \"SHF TRADE TD LTD\",\n",
    "    \"NEAT AUTOS LTD\",\n",
    "    \"SUPERIORCARUSO SERVICE\",\n",
    "    \"MOTOR & TRANSMISSIONSTEKNIK\",\n",
    "    \"RAIN GROUP TRADING FZE\",\n",
    "    \"LUCAS DIESEL Inyeccion Diesel\",\n",
    "    \"SURIPE_x001a_S - IMPORTA_x001a_O E\",\n",
    "    \"AOI SOLUTIONS GMBH\",\n",
    "    \"MARIO SPITERI PARTS & SERVICE\",\n",
    "    \"HOLSTEIN-HANDEL\",\n",
    "    \"RAY CINI TRANS\",\n",
    "    \"GAMMA TECHNICAL CORPORATION\",\n",
    "    \"GOBITRADE LTD.\",\n",
    "    \"CARPARTS IMPORT EXPORT KFT\",\n",
    "    \"REMANTE GROUP S.R.O.\",\n",
    "    \"PURIC D.O.O.\",\n",
    "    \"FERDINAND BILSTEIN UK LTD\",\n",
    "    \"ATLANTIC SPARE PARTS\",\n",
    "    \"GEZAIRI CO. Attn: Mr. Halo\",\n",
    "    \"RECANPRI, S.L.\",\n",
    "    \"SPH - SPARE PARTS HOUSE LDA\",\n",
    "    \"DELPHI DIESEL AFTERMARKET\",\n",
    "    \"PRESTOLITE ELECTRIC LIMITED\",\n",
    "    \"AVESA S.L.\",\n",
    "    \"TECNODIESEL MURCIA S.L.\",\n",
    "    \"MERLIN DIESEL SYSTEMS LTD\",\n",
    "    \"MERLIN DIESEL SYSTEM LTD\",\n",
    "    \"AMAZON EU S.A.R.L.\",\n",
    "    \"JOHN'S DIESEL SERVICE'S SQAQ\",\n",
    "    \"S.C DIESEL SOF S.R.L. STR\",\n",
    "    \"ARROWTRONIC LTD-EMS\",\n",
    "    \"HORIZON PROCUREMENTS\",\n",
    "    \"SARL PROIETTI FARNESE\",\n",
    "    \"TYRONE DIESEL SYSTEMS\",\n",
    "    \"DIESELWELT BRENNER GMBH\",\n",
    "    \"TURBOTECNIC AUTOMOCIO S.L.\",\n",
    "    \"KUNSHAN POWER ASIA IMPORT &\",\n",
    "    \"ORION PART OTOM.IC VE DIS\",\n",
    "    \"GUANGZHOU BAISITE AUTO PARTS\",\n",
    "    \"IPT OTOMOTIV DIS TICARET\",\n",
    "    \"KONING TECHNISCH BEDRIJF B.V.\",\n",
    "    \"PORTLAOISE DIESEL INJECTION\",\n",
    "    \"CORCORANS ENGINEERING\",\n",
    "    \"ZHENGZHOU LISERON OIL PUMP &\",\n",
    "    \"LKV TEKNIK OTOMOTIV SANAYI IC\",\n",
    "    \"GUANGDONG TOPWAY TECH CO LTD\",\n",
    "    \"UNITED FUEL INJECTION\",\n",
    "    \"LA CASA DEL DIESEL S.L.\",\n",
    "    \"OTT-PUTIAN DIESEL SPARE PARTS\",\n",
    "    \"AUTORAK SP. Z.O.O.\",\n",
    "    \"IB TRADE\",\n",
    "    \"FLOTA SUARDIAZ S.L.U.\",\n",
    "    \"2T + M KFT\",\n",
    "    \"KENDIESEL\",\n",
    "    \"CASTY-ROMER S.L.\",\n",
    "    \"DIESELSERVICE STOKKING B.V.\",\n",
    "    \"SUPER ENGINEERING WORKS\",\n",
    "    \"DIJITAL PARCA PLATFORMU SATIS\",\n",
    "    \"GOODAPP\",\n",
    "    \"INJECCIO DIESEL JORDA, S.L\",\n",
    "    \"GUNEYBAGLILAR OTO YEDEK PAR.\",\n",
    "    \"D. HAUPT GMBH\",\n",
    "    \"ASIST OTO YEDEK PARCA SANAYI\",\n",
    "    \"UHURU MAX LIMITED\",\n",
    "    \"SYDNEY DIESEL CENTRE\",\n",
    "    \"TALLERES RUFRE S.L.\",\n",
    "    \"AB IMPORTS\",\n",
    "    \"FACEWORKS LIMITED\",\n",
    "    \"William Psaila\",\n",
    "    \"EURO PARTS TRUCKS & BUSES\",\n",
    "    \"PORTLAOISE DIESEL LTD\",\n",
    "    \"SUARDIAZ MANAGEMENT SERVICES\",\n",
    "    \"EAST HOI TRADING COMPANY FLAT\",\n",
    "    \"Karadaglar group otomotiv\",\n",
    "    \"KARCOM LTD\",\n",
    "    \"ERB ITALY SRL\",\n",
    "    \"A.F. BAEDER GES.M.B.H.\",\n",
    "    \"DIESEL INJECTOR REPAIR Ltd\",\n",
    "    \"FAHRENHEIT LOGISTICS LIMITED\",\n",
    "    \"S T EARTHMOVING SERVICES\",\n",
    "    \"GOLDFARB and ASSOCIATES\",\n",
    "    \"PANDIESEL AEBE\",\n",
    "    \"ADF DIESEL\",\n",
    "    \"AutoDieselPart LLC\",\n",
    "    \"Goldfarb & Associates, Inc\",\n",
    "]\n",
    "\n",
    "# Loop through each file and process it\n",
    "for file_path in file_paths:\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(file_path, encoding=\"ISO-8859-1\")\n",
    "\n",
    "    # If you're working with the 'LISTA' column before renaming\n",
    "    df[\"LISTA\"] = df[\"LISTA\"].apply(\n",
    "        lambda x: int(x.split(\"/\")[1]) if \"/\" in x else int(x)\n",
    "    )\n",
    "\n",
    "    # Fix warranty, trasporto, imballo, and eco friendly issues\n",
    "    df[\"CODICE_ART\"] = df[\"CODICE_ART\"].str.upper()\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"].str.contains(\"warranty\", case=False, na=False)\n",
    "        & df[\"CODICE_ART\"].isin([\"\", \".\", \"NC\", \"nc\"]),\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"WARRANTY\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"].str.contains(\"trasporto|TRASPORTO\", case=False, na=False)\n",
    "        & df[\"CODICE_ART\"].isin([\"\", \".\", \"NC\", \"nc\", \"SPESE\", \"EXTRA\", \"TRASPORTO\"]),\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"SHIPREGULAR\", \"Aziendale\"]\n",
    "    # Print rows before applying condition\n",
    "    print(\"Before applying 'imballo' condition:\")\n",
    "    print(\n",
    "        df[\n",
    "            df[\"DESCRIZIONE_ART\"].str.contains(\n",
    "                r\"\\bimballo\\b|\\bIMBALLO\\b\", case=False, na=False\n",
    "            )\n",
    "        ][[\"DESCRIZIONE_ART\", \"CODICE_ART\", \"MARCA_ART\"]]\n",
    "    )\n",
    "\n",
    "    # Apply the 'imballo' condition\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"].str.contains(\n",
    "            r\"\\bimballo\\b|\\bIMBALLO\\b\", case=False, na=False\n",
    "        )\n",
    "        & df[\"CODICE_ART\"].isin([\"\", \".\", \"NC\", \"nc\", \"EXTRA\", \"IMBALLO\"]),\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"PACKING01\", \"Aziendale\"]\n",
    "\n",
    "    # Print rows after applying condition\n",
    "    print(\"After applying 'imballo' condition:\")\n",
    "    print(\n",
    "        df[\n",
    "            df[\"DESCRIZIONE_ART\"].str.contains(\n",
    "                r\"\\bimballo\\b|\\bIMBALLO\\b\", case=False, na=False\n",
    "            )\n",
    "        ][[\"DESCRIZIONE_ART\", \"CODICE_ART\", \"MARCA_ART\"]]\n",
    "    )\n",
    "\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"].str.contains(\n",
    "            \"ECO FRIENDLY|ECO-FRIENDLY|INIZIATIVA ECO-FRIENDLY|PROGETTO ECOFRIENDLY - TRASPORTO GR\",\n",
    "            case=False,\n",
    "            na=False,\n",
    "        ),\n",
    "        [\"CODICE_ART\", \"MARCA_ART\", \"DESCRIZIONE_ART\"],\n",
    "    ] = [\"PROMOECO\", \"Aziendale\", \"ECO FRIENDLY\"]\n",
    "\n",
    "    # Fix specific values in DESCRIZIONE_ART\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"].str.contains(\n",
    "            \"PREMIO FATTURATO|premio\", case=False, na=False\n",
    "        ),\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"PROMOCONTRACT01\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"].str.contains(\"INSOLUTO|INSOLUTI\", case=False, na=False),\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"INSOLUTO\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"accredito per err.applic.penale\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"ACCERR20240417\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"errato addeb. spese di incasso\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"EXPSHIPERR20240614\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"MANODOPERA STACCO/RIATT CON PRESSA\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"ACCMANODOP01\", \"RCS\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"].str.contains(\n",
    "            \"SBLOCCANTE WD40|WD-40 SBLOCCANTE|WD-40 SBLOCCANTE \", case=False, na=False\n",
    "        ),\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"490040\", \"WD-40\"]\n",
    "\n",
    "    # Additional condition for SPESE URGENZA\n",
    "    df.loc[\n",
    "        df[\"CODICE_ART\"] == \"SPESE URGENZA\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\", \"DESCRIZIONE_ART\"],\n",
    "    ] = [\"SHIPURGENT\", \"Aziendale\", \"TRASPORTO URGENTE\"]\n",
    "\n",
    "    # Fix specific values in CODICE_ART\n",
    "    df.loc[\n",
    "        df[\"CODICE_ART\"].isin([\"TBF1214035\", \"TBF1414035\"])\n",
    "        & df[\"MARCA_ART\"].isin([\"NC\", \".\", \"nc\"]),\n",
    "        \"MARCA_ART\",\n",
    "    ] = \"RCS\"\n",
    "    df.loc[\n",
    "        (df[\"CODICE_ART\"] == \"26870\") & df[\"MARCA_ART\"].isin([\"NC\", \".\", \"nc\"]),\n",
    "        \"MARCA_ART\",\n",
    "    ] = \"FEBI\"\n",
    "    df.loc[\n",
    "        (df[\"CODICE_ART\"] == \"3182654192\") & df[\"MARCA_ART\"].isin([\"NC\", \".\", \"nc\"]),\n",
    "        \"MARCA_ART\",\n",
    "    ] = \"SACHS\"\n",
    "\n",
    "    # Fix IMPOSTA OLIO in DESCRIZIONE_ART\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"].str.contains(\"IMPOSTA OLIO\", case=False, na=False),\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"OILVAT\", \"TAX\"]\n",
    "\n",
    "    # Additional conditions\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"].str.contains(\n",
    "            \"BONUS15|BONUS_15|BONUS_25|BONUS-15\", case=False, na=False\n",
    "        ),\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"PROMOBONUS01\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"].str.contains(\n",
    "            \"ASSICURAZIONE 6% CASCO|ASSICURAZIONE 4033195 6%|ASSICURAZIONE\",\n",
    "            case=False,\n",
    "            na=False,\n",
    "        ),\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"ASSICURAZIONE\", \"Aziendale\"]\n",
    "    df.loc[df[\"DESCRIZIONE_ART\"] == \"periodo q4/2023\", [\"CODICE_ART\", \"MARCA_ART\"]] = [\n",
    "        \"BOSCCORPQ42023\",\n",
    "        \"Aziendale\",\n",
    "    ]\n",
    "    df.loc[df[\"DESCRIZIONE_ART\"] == \"PERIODO Q3/2023\", [\"CODICE_ART\", \"MARCA_ART\"]] = [\n",
    "        \"BOSCCORPQ32023\",\n",
    "        \"Aziendale\",\n",
    "    ]\n",
    "    df.loc[df[\"DESCRIZIONE_ART\"] == \"PERIODO Q1/2024\", [\"CODICE_ART\", \"MARCA_ART\"]] = [\n",
    "        \"BOSCORPQ12024\",\n",
    "        \"Aziendale\",\n",
    "    ]\n",
    "\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"Kit tubaz/flessib Mercedes\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"Unknown\", \"MERCEDES\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"PACKAGING\",\n",
    "        [\"CODICE_ART\", \"DESCRIZIONE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"PACKING01\", \"IMBALLO\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"Urgenza Bosch\",\n",
    "        [\"CODICE_ART\", \"DESCRIZIONE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"PACKING01\", \"IMBALLO\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"PROVA AL BANCO INIETT DENSO C.R.\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"ORDMANO01\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"INIETT 0445110351\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"0445110351\", \"BOSCH\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"INIETT 0445110351 REVIS.\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"0986435204\", \"BOSCH\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"EUROTECH 95006227\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"95006227\", \"EUROTEC\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"SCONTO SU CONTEGGI\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"PROMOCOUNT\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"VENDITA BATTERIE ESAUSTE\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"ORDEXIDE20240510\", \"Aziendale\"]\n",
    "    df.loc[df[\"DESCRIZIONE_ART\"] == \"IMPORTO ADDEBITO\", [\"CODICE_ART\", \"MARCA_ART\"]] = [\n",
    "        \"ACCPEN01\",\n",
    "        \"Aziendale\",\n",
    "    ]\n",
    "\n",
    "    # Fix specific values in DESCRIZIONE_ART for unique conditions\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"ASSEGNO IMPAGATO N 0214310167\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"ACC0214310167\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"ASSEGNO IMPAG N 100593023 DEL 07/06\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"ACC100593023\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"accredito per err.applic.penale\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"ACCERR20240417\", \"Aziendale\"]\n",
    "    df.loc[df[\"DESCRIZIONE_ART\"] == \"INCASSO, VARIE\", [\"CODICE_ART\", \"MARCA_ART\"]] = [\n",
    "        \"ACC20240318\",\n",
    "        \"Aziendale\",\n",
    "    ]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"INDICARE MOTIVAZIONE\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"ACCERRU\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"SCONTO NON INDICATO\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"ACCERR\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"SPEDIZIONI ERRATE\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"ACCERRSHIP\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"errato importo trasporto\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"ACCERRSHIP\", \"Aziendale\"]\n",
    "\n",
    "    # SHIP conditions\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"1/2TRASPORTO INTERCONTIN.\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"SHIPINTERNATIONAL\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO URGENTE ENGLAND\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"SHIPINTERNATIONAL\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO URGENTE estero\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"SHIPINTERNATIONAL\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO URGENTE ESTERO\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"SHIPINTERNATIONAL\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO DA ESTERO\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"SHIPINTERNATIONAL\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO URGENTE GERMANY\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"SHIPINTERNATIONAL\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"DA E PER FORNITORE\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"SHIPSUPPLIER\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO DA FORNITORE\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"SHIPSUPPLIER\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO da fornitore\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"SHIPSUPPLIER\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO CON SPONDA\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"SHIPSPONDA\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"accredito per spese trasporto \",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"ACCSHIPERR\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"storno spese di trasporto\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"ACCSHIPERR\", \"Aziendale\"]\n",
    "    df.loc[df[\"DESCRIZIONE_ART\"] == \"TRASPORTO BRT\", [\"CODICE_ART\", \"MARCA_ART\"]] = [\n",
    "        \"SHIPBRT\",\n",
    "        \"Aziendale\",\n",
    "    ]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO a destinatario\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"SHIPREGULAR\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO URGENTE BH\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"SHIPBH\", \"Aziendale\"]\n",
    "    df.loc[df[\"DESCRIZIONE_ART\"] == \"TRASPORTO BH\", [\"CODICE_ART\", \"MARCA_ART\"]] = [\n",
    "        \"SHIPBH\",\n",
    "        \"Aziendale\",\n",
    "    ]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"trasporto  da BH\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\", \"QUANTITA\", \"PREZZO\", \"VAL_MERCE\", \"ULTIMO_ACQ\"],\n",
    "    ] = [\"SHIPBH\", \"Aziendale\", 1, 25, 25, 20.5]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO DA E PER FORNITORE\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"SHIPSUPPLIER\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"trasporto da e per Fornitore\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"SHIPSUPPLIER\", \"Aziendale\"]\n",
    "    df.loc[df[\"DESCRIZIONE_ART\"] == \"Trasporto delphi\", [\"CODICE_ART\", \"MARCA_ART\"]] = [\n",
    "        \"SHIPSUPPLIER\",\n",
    "        \"Aziendale\",\n",
    "    ]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO AEREO DA FORNITORE\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"SHIPSUPPLIERURGENT\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO 50 EURO \",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\", \"VAL_MERCE\", \"ULTIMO_ACQ\"],\n",
    "    ] = [\"SHIPURGENT\", \"Aziendale\", 50, 45]\n",
    "\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"Servizi Extra Trasporto Vasca racco\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"SHIPREGULAR\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASFERTA PRESSO VS SEDE\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"SHIPREGULAR\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASP. GLS RIF DDT 14 DEL 08/05/24\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\", \"QUANTITA\", \"PREZZO\", \"VAL_MERCE\", \"ULTIMO_ACQ\"],\n",
    "    ] = [\"SHIPBH\", \"Aziendale\", 1, 37, 22, 37]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO URGENTE 3,8%\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"SHIPURGENT\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO URGENTE 3.8%\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"SHIPURGENT\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"SPESE TRASPORTO URGENZA \", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"SHIPURGENT\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO URGENZA \", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"SHIPURGENT\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"SPESE TRASPORTO URGENTE\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"SHIPURGENT\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO SPESE URGENTI\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"SHIPURGENT\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"SPESE TRASPORTO UREGENTE\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"SHIPURGENT\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO URGENTE 2359.000\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"SHIPURGENT\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"trasporto urgente\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"SHIPURGENT\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO URGENTE \",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"SHIPURGENT\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"Trasporto da Fornitore\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"SHIPSUPPLIER\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"Trasporto Urgente\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"SHIPURGENT\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO URGENTE polv+ centralina\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"SHIPURGENT\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO OMAGGIO\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"PROMOSHIP\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO EXTRA URGENZA\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"SHIPURGENT\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO URGENTE 4%\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"SHIPURGENT\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO URGENTE\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"SHIPURGENT\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"Trasporto urgente da Bosch\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"SHIPSUPPLIERURGENT\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO URGENTE DA BOSCH\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"SHIPSUPPLIERURGENT\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO URGENTE DA FORNITORE\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"SHIPSUPPLIERURGENT\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO URGENTE DA ESTERO\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"SHIPINTERNATIONAL\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO DA FORNITORE ESTERO\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"SHIPINTERNATIONAL\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"Trasporto da Fornitore Estero\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"SHIPINTERNATIONAL\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"SPESE TRASPORTO UREGENTI\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"SHIPURGENT\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"SPESE TRASPORTO URGENTI\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"SHIPURGENT\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"Trasporto da e per Fornitore\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"SHIPINTERNATIONAL\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"TRASPORTO URGENTE ALBERO DA ESTERO\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"SHIPINTERNATIONAL\", \"Aziendale\"]\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"].str.contains(\"TRASPORTO DHL\", case=False, na=False),\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"SHIPDHL\", \"Aziendale\"]\n",
    "\n",
    "    # More conditions\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"PROVA AL BANCO INIET DENSO\",\n",
    "        [\"CODICE_ART\", \"MARCA_ART\"],\n",
    "    ] = [\"RCSORDSCIAB20243001\", \"Aziendale\"]\n",
    "\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"].isin(\n",
    "            [\n",
    "                \"SPESE TRASORTO URGENTE\",\n",
    "                \"SPESE TRSPORTO URGENTI\",\n",
    "                \"SPESE URGENTI\",\n",
    "                \"SPESE TRSPORTO URGENTE\",\n",
    "            ]\n",
    "        ),\n",
    "        \"CODICE_ART\",\n",
    "    ] = \"SHIPURGENT\"\n",
    "\n",
    "    df.loc[df[\"DESCRIZIONE_ART\"] == \"spese\", [\"CODICE_ART\", \"MARCA_ART\"]] = [\n",
    "        \"PACKING01\",\n",
    "        \"Aziendale\",\n",
    "    ]\n",
    "\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"] == \"STORNO SPESE INCASSO\", [\"CODICE_ART\", \"MARCA_ART\"]\n",
    "    ] = [\"ACC01\", \"Aziendale\"]\n",
    "\n",
    "    # One last logic pass to check for imballo and trasporto remnants\n",
    "\n",
    "    df.loc[\n",
    "        (df[\"CODICE_ART\"] == \"trasporto\") & (df[\"DESCRIZIONE_ART\"] == \"\"),\n",
    "        [\"CODICE_ART\", \"DESCRIZIONE_ART\"],\n",
    "    ] = [\"SHIPREGULAR\", \"TRASPORTO\"]\n",
    "    df.loc[\n",
    "        (df[\"CODICE_ART\"] == \"SPESE\") & (df[\"DESCRIZIONE_ART\"] == \"IMBALLO\"),\n",
    "        [\"CODICE_ART\", \"DESCRIZIONE_ART\"],\n",
    "    ] = [\"PACKING01\", \"IMBALLO\"]\n",
    "\n",
    "    # Debugging before changes\n",
    "    print(\"Before changes:\")\n",
    "    print(df[(df['RAGIONE_SOCIALE'] == 'MESSIDER S.R.L.') & (df['CODICE_ART'] == '42538404')])\n",
    "    print(df[(df['RAGIONE_SOCIALE'] == 'ESCOPAZZO TRUCK S.R.L.S.') & (df['CODICE_ART'] == '42538404')])\n",
    "\n",
    "    # Apply changes\n",
    "    df.loc[(df['RAGIONE_SOCIALE'] == 'MESSIDER S.R.L.') & (df['CODICE_ART'] == '42538404'), 'ULTIMO_ACQ'] = 34.76\n",
    "    df.loc[(df['RAGIONE_SOCIALE'] == 'ESCOPAZZO TRUCK S.R.L.S.') & (df['CODICE_ART'] == '42538404'), 'ULTIMO_ACQ'] = 34.76\n",
    "\n",
    "    # Debugging after changes\n",
    "    print(\"After changes:\")\n",
    "    print(df[(df['RAGIONE_SOCIALE'] == 'MESSIDER S.R.L.') & (df['CODICE_ART'] == '42538404')])\n",
    "    print(df[(df['RAGIONE_SOCIALE'] == 'ESCOPAZZO TRUCK S.R.L.S.') & (df['CODICE_ART'] == '42538404')])\n",
    "\n",
    "\n",
    "\n",
    "    # Set ULTIMO_ACQ to 0 for specific DESCRIZIONE_ART values\n",
    "    df.loc[\n",
    "        df[\"DESCRIZIONE_ART\"].str.contains(\n",
    "            \"WD40|WD-40|WARRANTY|IMPOSTA OLIO|IMBALLO|TRASPORTO|PACKAGING|Urgenza Bosch\",\n",
    "            case=False,\n",
    "            na=False,\n",
    "        ),\n",
    "        \"ULTIMO_ACQ\",\n",
    "    ] = 0\n",
    "\n",
    "    # Assign AGENTE value of 60 for 'CLIENTE DA WEB'\n",
    "    df.loc[df[\"RAGIONE_SOCIALE\"] == \"CLIENTE DA WEB\", \"AGENTE\"] = 60\n",
    "\n",
    "    # Assign placeholder Codice Agente for any remaining missing or zero values\n",
    "    df[\"AGENTE\"] = df[\"AGENTE\"].apply(lambda x: \"100\" if pd.isna(x) or x == 0 else x)\n",
    "\n",
    "    # Assign AG 50 for foreign \"RAGIONE SOCIALE\"\n",
    "    df[\"AGENTE\"] = df.apply(\n",
    "        lambda row: \"50\"\n",
    "        if row[\"RAGIONE_SOCIALE\"] in foreign_ragione_sociale\n",
    "        else row[\"AGENTE\"],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Verify that no 'AGENTE' values are missing\n",
    "    missing_agente_after = df[\"AGENTE\"].isna().sum()\n",
    "    print(f\"Missing 'AGENTE' after filling: {missing_agente_after}\")\n",
    "\n",
    "    # Assign 'MARCA_ART' to 'Aziendale' for specific 'CODICE_ART' values\n",
    "    df.loc[\n",
    "        df[\"CODICE_ART\"].str.contains(\n",
    "            \"EXTRA|ASSICURAZIONE|PENALE|ABBONAM-TRASP-0001|OMAGGIO|SPESE|TRASPORTO|WARRANTY\",\n",
    "            case=False,\n",
    "            na=False,\n",
    "        ),\n",
    "        \"MARCA_ART\",\n",
    "    ] = \"Aziendale\"\n",
    "\n",
    "    # Separate the rows to be dropped\n",
    "    dropped_df = df[df['MARCA_ART'].isin(['NC', '.', '', 'nc','BEX','RESO'])]\n",
    "    dropped_df_list.append(dropped_df)\n",
    "\n",
    "    # Drop entries where 'MARCA_ART' is 'NC' or '.' or empty\n",
    "    filtered_df = df[~df['MARCA_ART'].isin(['NC', '.', '', 'nc','BEX','RESO'])]\n",
    "\n",
    "    # Group by 'Ragione Sociale Cliente' and sort each group by 'Data Documento Precedente'\n",
    "    filtered_df[\"DATA_MOV\"] = pd.to_datetime(\n",
    "        filtered_df[\"DATA_MOV\"], format=\"%d/%m/%Y\", errors=\"coerce\"\n",
    "    )\n",
    "    grouped = filtered_df.groupby([\"RAGIONE_SOCIALE\"])\n",
    "    sorted_df = grouped.apply(\n",
    "        lambda x: x.sort_values(by=\"DATA_MOV\", ascending=True)\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    # Keep specific columns and rename them\n",
    "    columns_to_keep = {\n",
    "        \"DATA_MOV\": \"Data Documento Precedente\",\n",
    "        \"LISTA\": \"Numero Lista\",\n",
    "        \"MESE\": \"Mese\",\n",
    "        \"ANNO\": \"Anno\",\n",
    "        \"RAGIONE_SOCIALE\": \"Ragione Sociale Cliente\",\n",
    "        \"CLIENTE\": \"Codice Cliente\",\n",
    "        \"AGENTE\": \"Codice Agente\",\n",
    "        \"CODICE_ART\": \"Codice Articolo\",\n",
    "        \"MARCA_ART\": \"Marca Articolo\",\n",
    "        \"DESCRIZIONE_ART\": \"Descrizione Articolo\",\n",
    "        \"QUANTITA\": \"Quantita\",\n",
    "        \"VAL_MERCE\": \"Valore\",\n",
    "        \"ULTIMO_ACQ\": \"Costo\",\n",
    "        \"PREZZO\": \"Prezzo Articolo\",\n",
    "    }\n",
    "    cleaned_df = filtered_df[columns_to_keep.keys()].rename(columns=columns_to_keep)\n",
    "\n",
    "    # Update 'Costo' based on 'Prezzo Articolo'\n",
    "    cleaned_df[\"Costo\"] = cleaned_df.apply(\n",
    "        lambda row: row[\"Prezzo Articolo\"] * 0.9\n",
    "        if pd.isna(row[\"Costo\"]) or row[\"Costo\"] == 0 and row[\"Prezzo Articolo\"] > 0\n",
    "        else 0\n",
    "        if pd.isna(row[\"Costo\"]) or row[\"Costo\"] == 0 and row[\"Prezzo Articolo\"] == 0\n",
    "        else abs(row[\"Prezzo Articolo\"])\n",
    "        if pd.isna(row[\"Costo\"]) or row[\"Costo\"] == 0 and row[\"Prezzo Articolo\"] < 0\n",
    "        else row[\"Costo\"],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Append the cleaned dataframe to the list\n",
    "    df_list.append(cleaned_df)\n",
    "\n",
    "# Concatenate all the dataframes\n",
    "final_df = pd.concat(df_list, ignore_index=True)\n",
    "dropped_final_df = pd.concat(dropped_df_list, ignore_index=True)\n",
    "\n",
    "# Save the cleaned dataset to a new Excel file\n",
    "cleaned_file_path = \"Z:/My Drive/rcs/business analyst/Year2024-StatsSoFar-cleaned.xlsx\"\n",
    "final_df.to_excel(cleaned_file_path, index=False)\n",
    "\n",
    "# Save the dropped dataset to a new CSV file\n",
    "dropped_file_path = \"Z:/My Drive/rcs/business analyst/Year2024-StatsSoFar-dropped.csv\"\n",
    "dropped_final_df.to_csv(dropped_file_path, index=False)\n",
    "\n",
    "# Convert to JSON format\n",
    "json_file_path = \"Z:/My Drive/rcs/business analyst/Year2024-StatsSoFar-cleaned.json\"\n",
    "final_df.to_json(json_file_path, orient=\"records\", date_format=\"iso\")\n",
    "\n",
    "print(\"Cleaning process completed and saved to\", cleaned_file_path)\n",
    "print(\"Dropped data saved to\", dropped_file_path)\n",
    "print(\"JSON file saved to\", json_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#MINIFY MAIN DATASET#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_file_path = \"frontend\\public\\data\\datasetsfrom01JANto12JUN.json\"  # Path to your dataset JSON file\n",
    "output_file_path = \"frontend\\public\\data\\datasetsfrom01JANto12JUN.min.json\"  # Path for the minified JSON file\n",
    "\n",
    "with open(input_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "minified_json = json.dumps(data, separators=(\",\", \":\"))\n",
    "\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(minified_json)\n",
    "\n",
    "print(\"Minified JSON file created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#MINIFY CLIENTS DATASET#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_file_path = \"frontend\\public\\data\\clientdetailsdataset02072024.json\"  # Path to your dataset JSON file\n",
    "output_file_path = \"frontend\\public\\data\\clientdetailsdataset02072024.min.json\"  # Path for the minified JSON file\n",
    "\n",
    "with open(input_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "minified_json = json.dumps(data, separators=(\",\", \":\"))\n",
    "\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(minified_json)\n",
    "\n",
    "print(\"Minified JSON file created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
