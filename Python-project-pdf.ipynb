{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:80: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:80: SyntaxWarning: invalid escape sequence '\\ '\n",
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_19320\\1455470529.py:80: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  (\"Diagrammi Dettagliati\", \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'D:/coding/git-projects/rcs_management_stats/python.pdf'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fpdf import FPDF\n",
    "\n",
    "# Create instance of FPDF class\n",
    "pdf = FPDF()\n",
    "\n",
    "# Add a page\n",
    "pdf.add_page()\n",
    "\n",
    "# Set font\n",
    "pdf.set_font(\"Arial\", size = 12)\n",
    "\n",
    "# Add a cell\n",
    "pdf.cell(200, 10, txt = \"Schema del Progetto di Software di Gestione\", ln = True, align = 'C')\n",
    "\n",
    "# Add introductory text\n",
    "intro_text = \"\"\"\n",
    "Questo documento descrive i requisiti tecnici e il progetto di base per un software di gestione per una società B2B che si occupa di parti auto. Il software utilizzerà React, TypeScript e Bootstrap per il frontend, Node.js/Express.js per il backend, MongoDB per il database e Python per il motore statistico.\n",
    "\"\"\"\n",
    "pdf.multi_cell(0, 10, intro_text)\n",
    "\n",
    "# Add section headers and content\n",
    "sections = [\n",
    "    (\"Ruoli degli Utenti e Permessi\", \"\"\"\n",
    "- **Amministratore:**\n",
    "  - Accesso completo a tutte le funzionalità.\n",
    "  - Gestione di utenti, prodotti e promozioni.\n",
    "  - Visualizzazione e analisi di tutte le statistiche e gli avvisi.\n",
    "  - Visualizzazione della progressione e delle promozioni attive per tutti i clienti.\n",
    "\n",
    "- **Agente di Vendita:**\n",
    "  - Gestione delle promozioni.\n",
    "  - Visualizzazione delle statistiche dei clienti e degli avvisi per i clienti associati.\n",
    "  - Visualizzazione delle promozioni relative ai clienti associati.\n",
    "\n",
    "- **Cliente:**\n",
    "  - Visualizzazione della propria cronologia degli acquisti e delle statistiche di spesa.\n",
    "  - Visualizzazione delle promozioni disponibili.\n",
    "  - Visualizzazione della progressione verso le promozioni.\n",
    "    \"\"\"),\n",
    "    (\"Funzionalità Principali\", \"\"\"\n",
    "- **Gestione Clienti:**\n",
    "  - Tracciare le abitudini di spesa e la cronologia degli acquisti.\n",
    "  - Generare avvisi per clienti inattivi (visualizzabili solo da amministratori e agenti).\n",
    "  - Assegnare i clienti agli agenti (un cliente per agente, più clienti per agente).\n",
    "\n",
    "- **Gestione Promozioni:**\n",
    "  - Creare, inviare e gestire promozioni via SMS/Email.\n",
    "  - Tracciare la progressione verso le promozioni in base alla spesa.\n",
    "\n",
    "- **Gestione Ordini:**\n",
    "  - Importare ordini da file CSV.\n",
    "  - Futuro: Integrare con l'API di e-commerce per ottenere gli ordini direttamente.\n",
    "\n",
    "- **Statistiche e Avvisi:**\n",
    "  - Generare e visualizzare statistiche sul comportamento dei clienti e sulle vendite.\n",
    "  - Inviare avvisi per cambiamenti significativi nel comportamento dei clienti.\n",
    "    \"\"\"),\n",
    "    (\"Architettura di Alto Livello\", \"\"\"\n",
    "1. **Frontend:**\n",
    "   - **Framework:** React.js\n",
    "   - **Linguaggio:** TypeScript\n",
    "   - **Stile:** Bootstrap\n",
    "\n",
    "2. **Backend:**\n",
    "   - **Framework:** Node.js/Express.js\n",
    "   - **Database:** MongoDB\n",
    "   - **Autenticazione:** JWT, OAuth2\n",
    "   - **Parsing CSV:** Utilizzare una libreria come `csv-parser` per gestire i file CSV.\n",
    "   - **Integrazione API:** Predisposizione per l'integrazione con un'API di e-commerce.\n",
    "\n",
    "3. **Motore Statistico:**\n",
    "   - **Linguaggio:** Python\n",
    "   - **Librerie:** Pandas, NumPy, Scikit-learn\n",
    "   - **Comunicazione:** RabbitMQ per la coda dei messaggi\n",
    "\n",
    "4. **Deployment:**\n",
    "   - **Provider Cloud:** AWS, Azure, o Google Cloud\n",
    "   - **CI/CD:** Jenkins, GitHub Actions, o GitLab CI\n",
    "    \"\"\"),\n",
    "    (\"Diagrammi Dettagliati\", \"\"\"\n",
    "##### Diagramma dei Casi d'Uso\n",
    "\n",
    "                   +---------------------+\n",
    "                   |     Sistema di      |\n",
    "                   |    Gestione         |\n",
    "                   +---------------------+\n",
    "                    /      |       /      //\n",
    "                   /       |        /      //\n",
    "                  /        |         /      //\n",
    "                 /         |          /      //\n",
    "      +---------+          |           /      +---------+\n",
    "      | Amministratore |          |           /     | Cliente |\n",
    "      +---------+          |            /    +---------+\n",
    "           |               |             /       |\n",
    "  +--------v--------+ +----v-------v----+   +-----v-----+\n",
    "  | Gestione Utenti | | Gestione Promozioni | | Visualizza Statistiche |\n",
    "  +-----------------+ +-----------------+   +-----------+\n",
    "                           |\n",
    "                     +-----v-----+\n",
    "                     | Promozioni |\n",
    "                     +-----------+\n",
    "                           |\n",
    "                     +-----v-----+\n",
    "                     |  Ordini    |\n",
    "                     +-----------+\n",
    "    \"\"\"),\n",
    "    (\"Component Diagram\", \"\"\"\n",
    "##### Diagramma dei Componenti\n",
    "\n",
    " +-------------------+     +-------------------+\n",
    " |     Frontend      |     |      Backend      |\n",
    " | (React.js)        |<--> | (Node.js/Express) |\n",
    " +-------------------+     +-------------------+\n",
    "            |                      |\n",
    "            |                      |\n",
    "            v                      v\n",
    "    +--------------+        +-------------+\n",
    "    |   MongoDB    |        |   Python    |\n",
    "    +--------------+        +-------------+\n",
    "            |                      |\n",
    "            |                      |\n",
    "            v                      v\n",
    "        +---------+         +-------------+\n",
    "        | RabbitMQ|<------->| Python Stats|\n",
    "        +---------+         +-------------+\n",
    "            |\n",
    "            |\n",
    "        +---------+\n",
    "        | CSV/API |\n",
    "        +---------+\n",
    "    \"\"\"),\n",
    "    (\"Entity-Relationship Diagram (ERD)\", \"\"\"\n",
    "##### Diagramma Entità-Relazioni (ERD)\n",
    "\n",
    " +-------------+     +-------------+     +-------------+\n",
    " |  Cliente    |     |   Prodotto   |     | Promozione  |\n",
    " +-------------+     +-------------+     +-------------+\n",
    "        |                   |                   |\n",
    "        |                   |                   |\n",
    "        +-------------------+-------------------+\n",
    "                            |\n",
    "                            |\n",
    "                       +----------+\n",
    "                       |  Ordine  |\n",
    "                       +----------+\n",
    "                            |\n",
    "                       +----------+\n",
    "                       | Statistiche|\n",
    "                       +----------+\n",
    "                            |\n",
    "                       +----------+\n",
    "                       |   Agente  |\n",
    "                       +----------+\n",
    "    \"\"\"),\n",
    "    (\"Panoramica Funzionale\", \"\"\"\n",
    "#### Componenti del Frontend\n",
    "\n",
    "1. **Dashboard Amministratore:**\n",
    "   - Gestione Utenti: Aggiungere, modificare, eliminare utenti.\n",
    "   - Gestione Promozioni: Creare e inviare promozioni.\n",
    "   - Visualizzare Statistiche Clienti: Analisi e report dettagliati.\n",
    "   - Importazione Ordini: Caricare file CSV per importare ordini.\n",
    "   - Visualizzare e Gestire Avvisi.\n",
    "   - Visualizzare la progressione e le promozioni attive per tutti i clienti.\n",
    "\n",
    "2. **Dashboard Agente di Vendita:**\n",
    "   - Gestione Promozioni: Creare e inviare promozioni.\n",
    "   - Visualizzare Statistiche Clienti: Informazioni sul comportamento dei clienti associati.\n",
    "   - Visualizzare Avvisi: Notifiche per cambiamenti significativi nel comportamento dei clienti associati.\n",
    "   - Visualizzare Promozioni: Relativi ai clienti associati.\n",
    "\n",
    "3. **Dashboard Cliente:**\n",
    "   - Visualizzare Statistiche Personali: Accesso alla cronologia degli acquisti personali e alle statistiche di spesa.\n",
    "   - Visualizzare Promozioni: Accesso alle promozioni disponibili.\n",
    "   - Visualizzare Progressione: Progressione verso le promozioni.\n",
    "\n",
    "#### Servizi del Backend\n",
    "\n",
    "1. **Gestione Utenti:**\n",
    "   - Endpoint API per operazioni CRUD sugli utenti.\n",
    "   - Autenticazione e autorizzazione tramite JWT.\n",
    "   - Assegnare i clienti agli agenti.\n",
    "\n",
    "2. **Gestione Promozioni:**\n",
    "   - Endpoint API per creare e inviare promozioni via SMS/Email.\n",
    "   - Tracciare la progressione dei clienti verso le promozioni.\n",
    "\n",
    "3. **Gestione Ordini:**\n",
    "   - Endpoint API per caricare e analizzare file CSV.\n",
    "   - Servizio futuro per l'integrazione con l'API di e-commerce.\n",
    "\n",
    "4. **Gestione Statistiche e Avvisi:**\n",
    "   - Endpoint API per generare e recuperare statistiche.\n",
    "   - Integrazione con Python per analisi avanzate.\n",
    "    \"\"\"),\n",
    "    (\"Prossimi Passi\", \"\"\"\n",
    "1. **Definire gli Endpoint API:**\n",
    "   - Elencare tutti gli endpoint necessari per la gestione di utenti, promozioni, ordini e statistiche.\n",
    "   - Includere endpoint per il caricamento di file CSV e l'integrazione futura con l'API.\n",
    "\n",
    "2. **Configurare l'Ambiente Iniziale:**\n",
    "   - Configurare MongoDB, Node.js/Express, e le strutture del progetto React.\n",
    "   - Configurare RabbitMQ e l'ambiente Python.\n",
    "\n",
    "3. **Sviluppare le Funzionalità Core:**\n",
    "   - Implementare le funzionalità principali come l'autenticazione degli utenti, la gestione delle promozioni e il tracciamento base degli ordini.\n",
    "   - Assegnare i clienti agli agenti e gestire le associazioni.\n",
    "\n",
    "4. **Integrare la Gestione dei CSV:**\n",
    "   - Implementare la funzionalità di caricamento e analisi dei file CSV.\n",
    "\n",
    "5. **Pianificare l'Integrazione Futura con l'API:**\n",
    "   - Progettare il sistema in modo da poter passare facilmente dai caricamenti CSV alle chiamate API.\n",
    "   - Implementare un servizio di placeholder per l'integrazione con l'API.\n",
    "\n",
    "6. **Implementare il Frontend:**\n",
    "   - Creare componenti React per le dashboard di amministratori, agenti di vendita e clienti.\n",
    "\n",
    "7. **Test e Deployment:**\n",
    "   - Eseguire test approfonditi di tutte le funzionalità.\n",
    "   - Configurare una pipeline CI/CD per il deployment.\n",
    "    \"\"\")\n",
    "]\n",
    "\n",
    "for title, content in sections:\n",
    "    pdf.set_font(\"Arial\", size=12, style='B')\n",
    "    pdf.cell(0, 10, title, ln=True)\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "    pdf.multi_cell(0, 10, content)\n",
    "\n",
    "# Save the PDF\n",
    "pdf_output = \"D:/coding/git-projects/rcs_management_stats/project_basis.pdf\"\n",
    "pdf.output(pdf_output)\n",
    "\n",
    "pdf_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fpdf import FPDF\n",
    "\n",
    "class PDF(FPDF):\n",
    "    def header(self):\n",
    "        self.set_font('Arial', 'B', 12)\n",
    "        self.cell(0, 10, 'Piano di Implementazione', 0, 1, 'C')\n",
    "        self.ln(10)\n",
    "\n",
    "    def chapter_title(self, title):\n",
    "        self.set_font('Arial', 'B', 12)\n",
    "        self.cell(0, 10, title, 0, 1, 'L')\n",
    "        self.ln(4)\n",
    "\n",
    "    def chapter_body(self, body):\n",
    "        self.set_font('Arial', '', 12)\n",
    "        self.multi_cell(0, 10, body)\n",
    "        self.ln()\n",
    "\n",
    "    def add_chapter(self, title, body):\n",
    "        self.add_page()\n",
    "        self.chapter_title(title)\n",
    "        self.chapter_body(body)\n",
    "\n",
    "pdf = PDF()\n",
    "\n",
    "# Title\n",
    "pdf.set_title('Piano di Implementazione')\n",
    "\n",
    "# Content\n",
    "content = \"\"\"\n",
    "1. Panoramica delle Pagine e Componenti\n",
    "Costruiremo le seguenti pagine per agenti, amministratori e clienti:\n",
    "\n",
    "Pagina Clienti\n",
    "Pagina Visite\n",
    "Pagina Statistiche (In Costruzione)\n",
    "Pagina Promozioni\n",
    "Pagina Avvisi\n",
    "Pagina Ordini\n",
    "Pagina Articoli\n",
    "Pagina Crea Avviso\n",
    "Pagina Rapporto Visita\n",
    "Successivamente, creeremo i dashboard per amministratori e clienti:\n",
    "\n",
    "Dashboard Amministratore\n",
    "Dashboard Cliente\n",
    "\n",
    "2. Struttura delle Pagine e Componenti\n",
    "\n",
    "Pagina Clienti\n",
    "Componenti:\n",
    "Elenco Clienti: Visualizza un elenco di clienti.\n",
    "Ricerca e Filtri Clienti: Funzionalità di ricerca per filtrare i clienti per vari criteri (data, agente, cliente).\n",
    "Dettagli Cliente: Mostra informazioni dettagliate su un cliente selezionato.\n",
    "Storico Visite: Visualizza le note delle visite relative al cliente selezionato.\n",
    "Funzionalità:\n",
    "Vista Agente: Vede solo i clienti associati all'agente.\n",
    "Vista Amministratore: Vede tutti i clienti, con informazioni sugli agenti associati.\n",
    "Vista Cliente: Vede informazioni dettagliate su se stesso e lo storico delle visite.\n",
    "\n",
    "Pagina Visite\n",
    "Componenti:\n",
    "Elenco Visite: Visualizza un elenco paginato di visite (25 per pagina).\n",
    "Dettagli Visita: Mostra informazioni dettagliate su una visita selezionata.\n",
    "Modulo Rapporto Visita (Pagina Separata): Un modulo per agenti e clienti per riportare i dettagli sulla visita.\n",
    "Funzionalità:\n",
    "Vista Agente: Vede solo le visite relative all'agente. Le visite senza rapporti sono evidenziate.\n",
    "Vista Amministratore: Vede tutte le visite. Monitora i rapporti di visita in ritardo.\n",
    "Vista Cliente: Vede le visite relative al cliente. Può inviare un rapporto di visita.\n",
    "Avvisi automatizzati per i rapporti di visita in ritardo (24 ore dopo la visita).\n",
    "Visite modificabili: Gli agenti possono spostare o riprogrammare le visite. Questo genera un avviso per gli amministratori.\n",
    "Modulo Rapporto Visita: Diviso in una parte pubblica (visibile ai clienti) e una parte privata (visibile solo agli agenti e amministratori).\n",
    "\n",
    "Pagina Statistiche\n",
    "Componenti:\n",
    "In Costruzione: Segnaposto che indica che la pagina è in costruzione.\n",
    "\n",
    "Pagina Promozioni\n",
    "Componenti:\n",
    "Elenco Promozioni: Visualizza un elenco di promozioni attuali e passate.\n",
    "Dettagli Promozione: Mostra informazioni dettagliate su una promozione selezionata.\n",
    "Modulo Crea Promozione: Un modulo per creare nuove promozioni.\n",
    "Funzionalità:\n",
    "Vista Agente: Vede le promozioni relative ai clienti dell'agente.\n",
    "Vista Amministratore: Vede tutte le promozioni.\n",
    "Vista Cliente: Vede le promozioni relative a se stesso, se ha raggiunto gli obiettivi.\n",
    "\n",
    "Pagina Avvisi\n",
    "Componenti:\n",
    "Elenco Avvisi: Visualizza un elenco di avvisi (automatici e manuali).\n",
    "Dettagli Avviso: Mostra informazioni dettagliate su un avviso selezionato.\n",
    "Funzionalità:\n",
    "Vista Agente: Vede gli avvisi relativi all'agente.\n",
    "Vista Amministratore: Vede tutti gli avvisi. Crea e gestisce avvisi.\n",
    "Vista Cliente: Vede gli avvisi relativi a se stesso.\n",
    "\n",
    "Pagina Ordini\n",
    "Componenti:\n",
    "Elenco Ordini: Visualizza un elenco di ordini dei clienti.\n",
    "Dettagli Ordine: Mostra informazioni dettagliate su un ordine selezionato.\n",
    "Funzionalità:\n",
    "Vista Agente: Vede solo gli ordini dei clienti associati all'agente.\n",
    "Vista Amministratore: Vede tutti gli ordini dei clienti.\n",
    "Vista Cliente: Vede solo i propri ordini.\n",
    "Informazioni sugli articoli collegati agli ordini, comprese le promozioni utilizzate e lo stato dei debiti.\n",
    "\n",
    "Pagina Articoli\n",
    "Componenti:\n",
    "Elenco Articoli: Visualizza un elenco di articoli.\n",
    "Ricerca e Filtri Articoli: Funzionalità di ricerca e filtro per ordinare gli articoli (migliori vendite, ecc.).\n",
    "Dettagli Articolo: Mostra informazioni dettagliate su un articolo selezionato.\n",
    "Funzionalità:\n",
    "Vista Agente: Vede solo gli articoli relativi agli ordini dei clienti associati all'agente.\n",
    "Vista Amministratore: Vede tutti gli articoli.\n",
    "Vista Cliente: Vede solo gli articoli relativi ai propri ordini, con un link all'ordine relativo.\n",
    "Informazioni sugli articoli: numero OEM compatibile, ID del produttore, nome, descrizione, promozioni o coupon associati.\n",
    "Collegamento automatico degli articoli con lo stesso numero OEM.\n",
    "\n",
    "Pagina Crea Avviso\n",
    "Componenti:\n",
    "Modulo Crea Avviso: Un modulo per creare nuovi avvisi.\n",
    "Funzionalità:\n",
    "Vista Amministratore: Crea nuovi avvisi.\n",
    "\n",
    "Pagina Rapporto Visita\n",
    "Componenti:\n",
    "Modulo Rapporto Visita: Un modulo per riportare i dettagli su una visita.\n",
    "Funzionalità:\n",
    "Vista Agente: Invia rapporti di visita.\n",
    "Vista Cliente: Invia feedback su una visita.\n",
    "Parte Pubblica: Visibile ai clienti.\n",
    "Parte Privata: Visibile solo agli agenti e amministratori.\n",
    "\n",
    "3. Dashboard\n",
    "\n",
    "Dashboard Amministratore\n",
    "Componenti:\n",
    "Panoramica: Riepilogo delle metriche e delle statistiche chiave.\n",
    "Gestione Utenti: Gestisce agenti e clienti.\n",
    "Avvisi di Sistema: Visualizza avvisi e notifiche di sistema.\n",
    "Funzionalità:\n",
    "Visualizza statistiche generali del sistema.\n",
    "Gestisce gli utenti (agenti e clienti).\n",
    "Monitora avvisi e notifiche di sistema.\n",
    "Interagisce con tutte le funzionalità degli agenti per la supervisione amministrativa.\n",
    "\n",
    "Dashboard Cliente\n",
    "Componenti:\n",
    "Panoramica: Riepilogo dell'attività e delle statistiche del cliente.\n",
    "Storico Acquisti: Visualizza uno storico degli ordini del cliente.\n",
    "Promozioni Attive: Visualizza le promozioni attuali disponibili per il cliente.\n",
    "Abitudini di Spesa: Rappresentazione visiva delle abitudini di spesa del cliente.\n",
    "Funzionalità:\n",
    "Visualizza attività e statistiche personali.\n",
    "Accede allo storico degli acquisti.\n",
    "Visualizza promozioni attive.\n",
    "Monitora abitudini di spesa.\n",
    "Interazione con Promozioni e Avvisi per dati personalizzati.\n",
    "\n",
    "4. Tipi di Agenti\n",
    "- Agenti di Vendita: Gestiscono le vendite e il rapporto con i clienti.\n",
    "- Agenti di Vendita Tecnici: Forniscono supporto tecnico durante le vendite.\n",
    "- Agenti di Supporto Tecnico: Offrono supporto tecnico post-vendita.\n",
    "Nota: Tutti i tipi di agenti saranno trattati allo stesso modo all'interno dell'app. L'app verificherà il tipo di agente al momento del login e fornirà l'accesso alle funzioni richieste in base al loro ruolo.\n",
    "\n",
    "5. Piano di Implementazione\n",
    "\n",
    "Impostare le Rotte e i Componenti delle Pagine\n",
    "Definire le rotte per ogni pagina nei dashboard dell'agente, dell'amministratore e del cliente.\n",
    "Creare la struttura di base per ogni pagina.\n",
    "\n",
    "Implementare le Funzionalità per Ogni Pagina\n",
    "Pagina Clienti: Implementare ricerca clienti, filtri, dettagli e storico visite in base al tipo di utente loggato.\n",
    "Pagina Visite: Implementare elenco visite, dettagli e funzionalità di reporting. Automatizzare avvisi per rapporti in ritardo.\n",
    "Pagina Promozioni: Implementare elenco promozioni, dettagli e modulo di creazione con tracciamento dell'efficacia.\n",
    "Pagina Avvisi: Sviluppare elenco avvisi, dettagli e modulo di creazione con tracciamento della risoluzione.\n",
    "Pagina Ordini: Implementare elenco ordini, dettagli e informazioni sugli articoli.\n",
    "Pagina Articoli: Implementare elenco articoli, ricerca, filtri, dettagli e collegamenti automatici.\n",
    "Pagina Crea Avviso: Implementare il modulo per la creazione di nuovi avvisi da parte degli amministratori.\n",
    "Pagina Rapporto Visita: Implementare il modulo per l'invio di rapporti di visita da parte di agenti e clienti.\n",
    "\n",
    "Sviluppare i Dashboard\n",
    "Impostare le rotte e la struttura di base per i dashboard di amministratori e clienti.\n",
    "Implementare funzionalità specifiche e componenti per ogni dashboard.\n",
    "\n",
    "Integrare e Testare\n",
    "Assicurarsi che tutte le pagine e i componenti siano integrati e funzionali.\n",
    "Condurre test approfonditi per identificare e risolvere problemi.\n",
    "\n",
    "Esempio Dettagliato: Implementazione della Pagina Clienti\n",
    "Componenti:\n",
    "ClientsList.tsx: Visualizza un elenco di clienti.\n",
    "ClientSearchFilters.tsx: Filtra i clienti per data, agente, cliente.\n",
    "ClientDetails.tsx: Mostra informazioni dettagliate su un cliente selezionato.\n",
    "VisitsHistory.tsx: Visualizza le note delle visite relative al cliente selezionato.\n",
    "\n",
    "Interazione:\n",
    "Filtrare per cliente o data aggiorna il componente VisitsHistory per mostrare le note di visita pertinenti.\n",
    "\n",
    "Sommario del Piano Generale\n",
    "Pagina Clienti: Creare e integrare componenti con filtri e interazione cliente-visita.\n",
    "Pagina Visite: Implementare elenco visite, dettagli e funzionalità di reporting. Automatizzare avvisi per rapporti in ritardo.\n",
    "Pagina Promozioni: Implementare elenco promozioni, dettagli e modulo di creazione con tracciamento dell'efficacia.\n",
    "Pagina Avvisi: Sviluppare elenco avvisi, dettagli e modulo di creazione con tracciamento della risoluzione.\n",
    "Pagina Ordini: Implementare elenco ordini, dettagli e informazioni sugli articoli.\n",
    "Pagina Articoli: Implementare elenco articoli, ricerca, filtri, dettagli e collegamenti automatici.\n",
    "Dashboard Amministratore e Cliente: Personalizzare i dashboard con funzionalità e dati rilevanti.\n",
    "Pagina Crea Avviso: Implementare il modulo per la creazione di nuovi avvisi da parte degli amministratori.\n",
    "Pagina Rapporto Visita: Implementare il modulo per l'invio di rapporti di visita da parte di agenti e clienti.\n",
    "\n",
    "Seguendo questo piano strutturato, ci assicuriamo che tutte le funzionalità siano ben pensate e integrate senza problemi. Una volta che avremo un piano chiaro e comprensione, possiamo iniziare a codificare ogni componente passo dopo passo. Se hai domande specifiche o necessiti di ulteriori dettagli su qualsiasi parte, non esitare a chiedere!\n",
    "\"\"\"\n",
    "\n",
    "pdf.add_chapter('Piano di Implementazione', content)\n",
    "\n",
    "# Save the PDF to a file\n",
    "pdf.output('Piano_di_Implementazione.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Data Lista', 'Tipo Documento Attuale', 'Data Documento Attuale',\n",
      "       'Numero Documento Attuale', 'Lettera Documento Attuale',\n",
      "       'Tipo Documento Precedente', 'Data Documento Precedente',\n",
      "       'Numero Documento Precedente', 'Lettera Documento Precedente',\n",
      "       'Codice Cliente', 'Ragione Sociale Cliente', 'Codice Agente',\n",
      "       'Identificativo Articolo', 'Codice Articolo', 'Marca Articolo',\n",
      "       'Descrizione Articolo', 'Quantita Articolo', 'Prezzo Articolo',\n",
      "       'Valore', 'Mese', 'Anno', 'Costo', 'Gruppo Merceologico', 'Famiglia',\n",
      "       'Categoria Sconto Vendita', 'Reparto', 'Numero Lista'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_18188\\3502614722.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sorted_df = grouped.apply(sort_within_group).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file created successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from numpyencoder import NumpyEncoder\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'X:/artor/Downloads/mov_ven_01_06_2024.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Inspect the columns\n",
    "print(df.columns)\n",
    "\n",
    "# Group by 'Numero Documento Attuale' and 'Codice Cliente'\n",
    "grouped = df.groupby(['Numero Documento Attuale', 'Codice Cliente'])\n",
    "\n",
    "# Function to sort within groups\n",
    "def sort_within_group(group):\n",
    "    return group.sort_values(by=['Numero Lista'])\n",
    "\n",
    "# Apply sorting within each group\n",
    "sorted_df = grouped.apply(sort_within_group).reset_index(drop=True)\n",
    "\n",
    "# Convert the sorted DataFrame to a list of dictionaries\n",
    "def convert_to_json(df):\n",
    "    orders = []\n",
    "    \n",
    "    for (doc_num, client_code), group in df.groupby(['Numero Documento Attuale', 'Codice Cliente']):\n",
    "        movements = group.to_dict(orient='records')\n",
    "        order = {\n",
    "            'documentNumber': doc_num,\n",
    "            'clientCode': client_code,\n",
    "            'movements': movements\n",
    "        }\n",
    "        orders.append(order)\n",
    "    \n",
    "    return orders\n",
    "\n",
    "# Convert to JSON-like structure\n",
    "orders_json = convert_to_json(sorted_df)\n",
    "\n",
    "# Save the orders JSON to a file\n",
    "output_path = 'X:/artor/Downloads/json.json'\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(orders_json, f, indent=4, cls=NumpyEncoder)\n",
    "\n",
    "print(\"JSON file created successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Data Lista', 'Tipo Documento Attuale', 'Data Documento Attuale',\n",
      "       'Numero Documento Attuale', 'Lettera Documento Attuale',\n",
      "       'Tipo Documento Precedente', 'Data Documento Precedente',\n",
      "       'Numero Documento Precedente', 'Lettera Documento Precedente',\n",
      "       'Codice Cliente', 'Ragione Sociale Cliente', 'Codice Agente',\n",
      "       'Identificativo Articolo', 'Codice Articolo', 'Marca Articolo',\n",
      "       'Descrizione Articolo', 'Quantita Articolo', 'Prezzo Articolo',\n",
      "       'Valore', 'Mese', 'Anno', 'Costo', 'Gruppo Merceologico', 'Famiglia',\n",
      "       'Categoria Sconto Vendita', 'Reparto', 'Numero Lista'],\n",
      "      dtype='object')\n",
      "JSON file created successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from numpyencoder import NumpyEncoder\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'X:/artor/Downloads/mov_ven_01_06_2024.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Inspect the columns\n",
    "print(df.columns)\n",
    "\n",
    "# Function to sort within groups\n",
    "def sort_within_group(group):\n",
    "    return group.sort_values(by=['Numero Lista'])\n",
    "\n",
    "# Apply sorting by 'Ragione Sociale Cliente' and then group by 'Data Documento Attuale'\n",
    "df_sorted = df.sort_values(by=['Ragione Sociale Cliente', 'Data Documento Attuale'])\n",
    "\n",
    "# Group by 'Ragione Sociale Cliente' and 'Data Documento Attuale'\n",
    "grouped = df_sorted.groupby(['Ragione Sociale Cliente', 'Data Documento Attuale'])\n",
    "\n",
    "# Convert the sorted DataFrame to a list of dictionaries\n",
    "def convert_to_json(df):\n",
    "    orders = []\n",
    "    \n",
    "    for (client_name, doc_date), group in df.groupby(['Ragione Sociale Cliente', 'Data Documento Attuale']):\n",
    "        group_sorted = group.sort_values(by=['Numero Lista'])\n",
    "        movements = group_sorted.to_dict(orient='records')\n",
    "        order = {\n",
    "            'clientName': client_name,\n",
    "            'documentDate': doc_date,\n",
    "            'movements': movements\n",
    "        }\n",
    "        orders.append(order)\n",
    "    \n",
    "    return orders\n",
    "\n",
    "# Convert to JSON-like structure\n",
    "orders_json = convert_to_json(df_sorted)\n",
    "\n",
    "# Save the orders JSON to a file\n",
    "output_path = 'X:/artor/Downloads/json.json'\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(orders_json, f, indent=4, cls=NumpyEncoder)\n",
    "\n",
    "print(\"JSON file created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_18188\\1289265450.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sorted_df = grouped.apply(lambda x: x.sort_values(by='Data Documento Precedente')).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cleaned and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'X:/artor/Downloads/mov_ven_01_06_2024.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Sort by 'Numero Lista'\n",
    "df_sorted = df.sort_values(by=['Numero Lista'])\n",
    "\n",
    "# Group by 'Ragione Sociale Cliente'\n",
    "grouped = df_sorted.groupby(['Ragione Sociale Cliente'])\n",
    "\n",
    "# Sort each group by 'Data Documento Attuale'\n",
    "sorted_df = grouped.apply(lambda x: x.sort_values(by='Data Documento Precedente')).reset_index(drop=True)\n",
    "\n",
    "# Drop columns that are not useful for our purposes\n",
    "columns_to_keep = [\n",
    "    'Ragione Sociale Cliente', 'Codice Cliente','Codice Agente', 'Identificativo Articolo', 'Codice Articolo', 'Marca Articolo', 'Descrizione Articolo', 'Valore' , 'Mese', 'Anno', 'Costo', 'Numero Lista',\n",
    "    'Codice Cliente', 'Prezzo Articolo', 'Valore', 'Data Documento Precedente', 'Categoria Sconto Vendita'\n",
    "]\n",
    "\n",
    "# Save the cleaned DataFrame to a new Excel file\n",
    "output_path = 'X:/artor/Downloads/cleaned_mov_ven_01_06_2024.xlsx'\n",
    "cleaned_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(\"Dataset cleaned and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to convert the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_18188\\246304612.py:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sorted_df = grouped.apply(lambda x: x.sort_values(by='Data Documento Precedente')).reset_index(drop=True)\n",
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_18188\\246304612.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '<DatetimeArray>\n",
      "[]\n",
      "Length: 0, dtype: datetime64[ns]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  sorted_df.loc[missing_dates_mask, 'Data Documento Precedente'] = pd.to_datetime(\n",
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_18188\\246304612.py:22: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
      "  sorted_df['Codice Agente'] = sorted_df.groupby('Ragione Sociale Cliente')['Codice Agente'].fillna(method='ffill')\n",
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_18188\\246304612.py:22: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sorted_df['Codice Agente'] = sorted_df.groupby('Ragione Sociale Cliente')['Codice Agente'].fillna(method='ffill')\n",
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_18188\\246304612.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_df['Valore'] = cleaned_df['Valore'].str.replace(',', '.').astype(float)\n",
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_18188\\246304612.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_df['Costo'] = cleaned_df['Costo'].str.replace(',', '.').astype(float)\n",
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_18188\\246304612.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_df['Prezzo Articolo'] = cleaned_df['Prezzo Articolo'].str.replace(',', '.').astype(float)\n",
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_18188\\246304612.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_df['Data Documento Precedente'] = pd.to_datetime(cleaned_df['Data Documento Precedente'], format='%Y%m%d', errors='coerce')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'X:/artor/Downloads/mov_01-01-2024_to_12-06-2024_final.xlsx'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the original dataset\n",
    "file_path = \"X:/artor/Downloads/mov_ven_01_06_2024_original.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Sort by 'Numero Lista'\n",
    "df_sorted = df.sort_values(by=['Numero Lista'])\n",
    "\n",
    "# Group by 'Ragione Sociale Cliente' and sort each group by 'Data Documento Precedente'\n",
    "grouped = df_sorted.groupby(['Ragione Sociale Cliente'])\n",
    "sorted_df = grouped.apply(lambda x: x.sort_values(by='Data Documento Precedente')).reset_index(drop=True)\n",
    "\n",
    "# Fill missing 'Data Documento Precedente' using 'Mese' and 'Anno'\n",
    "missing_dates_mask = sorted_df['Data Documento Precedente'].isna()\n",
    "sorted_df.loc[missing_dates_mask, 'Data Documento Precedente'] = pd.to_datetime(\n",
    "    sorted_df.loc[missing_dates_mask, 'Anno'].astype(str) + '-' +\n",
    "    sorted_df.loc[missing_dates_mask, 'Mese'].astype(str) + '-01'\n",
    ")\n",
    "\n",
    "# Forward fill the 'Codice Agente' based on the most recent known value for each 'Ragione Sociale Cliente'\n",
    "sorted_df['Codice Agente'] = sorted_df.groupby('Ragione Sociale Cliente')['Codice Agente'].fillna(method='ffill')\n",
    "\n",
    "# Drop unnecessary columns, keep 'Categoria Sconto Vendita'\n",
    "columns_to_keep = [\n",
    "    'Ragione Sociale Cliente', 'Codice Cliente','Codice Agente', 'Identificativo Articolo', 'Codice Articolo', 'Marca Articolo', 'Descrizione Articolo', 'Valore' , 'Mese', 'Anno', 'Costo', 'Numero Lista',\n",
    "    'Prezzo Articolo', 'Data Documento Precedente', 'Categoria Sconto Vendita'\n",
    "]\n",
    "cleaned_df = sorted_df[columns_to_keep]\n",
    "\n",
    "# Convert numeric columns to appropriate data types\n",
    "cleaned_df['Valore'] = cleaned_df['Valore'].str.replace(',', '.').astype(float)\n",
    "cleaned_df['Costo'] = cleaned_df['Costo'].str.replace(',', '.').astype(float)\n",
    "cleaned_df['Prezzo Articolo'] = cleaned_df['Prezzo Articolo'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# Convert 'Data Documento Precedente' to datetime format\n",
    "cleaned_df['Data Documento Precedente'] = pd.to_datetime(cleaned_df['Data Documento Precedente'], format='%Y%m%d', errors='coerce')\n",
    "\n",
    "# Save the cleaned dataset to a new Excel file\n",
    "cleaned_file_path = \"X:/artor/Downloads/mov_01-01-2024_to_12-06-2024_final.xlsx\"\n",
    "cleaned_df.to_excel(cleaned_file_path, index=False)\n",
    "\n",
    "cleaned_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_23496\\537073587.py:13: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sorted_df = grouped.apply(lambda x: x.sort_values(by='Data Documento Precedente')).reset_index(drop=True)\n",
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_23496\\537073587.py:27: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
      "  sorted_df['Codice Agente'] = sorted_df.groupby('Ragione Sociale Cliente')['Codice Agente'].fillna(method='ffill')\n",
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_23496\\537073587.py:27: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sorted_df['Codice Agente'] = sorted_df.groupby('Ragione Sociale Cliente')['Codice Agente'].fillna(method='ffill')\n",
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_23496\\537073587.py:30: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
      "  sorted_df['Codice Agente'] = sorted_df.groupby('Ragione Sociale Cliente')['Codice Agente'].fillna(method='bfill')\n",
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_23496\\537073587.py:30: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sorted_df['Codice Agente'] = sorted_df.groupby('Ragione Sociale Cliente')['Codice Agente'].fillna(method='bfill')\n",
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_23496\\537073587.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  sorted_df['Codice Agente'].fillna(99, inplace=True)\n",
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_23496\\537073587.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_df['Valore'] = cleaned_df['Valore'].str.replace(',', '.').astype(float)\n",
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_23496\\537073587.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_df['Costo'] = cleaned_df['Costo'].str.replace(',', '.').astype(float)\n",
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_23496\\537073587.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_df['Prezzo Articolo'] = cleaned_df['Prezzo Articolo'].str.replace(',', '.').astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing 'Data Documento Precedente' after filling: 0\n",
      "Missing 'Codice Agente' after filling: 0\n",
      "Cleaning process completed and saved to X:/artor/Downloads/mov_01-01-2024_to_12-06-2024_finalv3.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the original dataset\n",
    "file_path = \"X:/artor/Downloads/mov_ven_01_06_2024_original.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Sort by 'Numero Lista'\n",
    "df_sorted = df.sort_values(by=['Numero Lista'])\n",
    "\n",
    "# Group by 'Ragione Sociale Cliente' and sort each group by 'Data Documento Precedente'\n",
    "df_sorted['Data Documento Precedente'] = pd.to_datetime(df_sorted['Data Documento Precedente'], format='%Y%m%d', errors='coerce')\n",
    "grouped = df_sorted.groupby(['Ragione Sociale Cliente'])\n",
    "sorted_df = grouped.apply(lambda x: x.sort_values(by='Data Documento Precedente')).reset_index(drop=True)\n",
    "\n",
    "# Fill missing 'Data Documento Precedente' using 'Mese' and 'Anno'\n",
    "missing_dates_mask = sorted_df['Data Documento Precedente'].isna()\n",
    "sorted_df.loc[missing_dates_mask, 'Data Documento Precedente'] = pd.to_datetime(\n",
    "    sorted_df.loc[missing_dates_mask, 'Anno'].astype(str) + '-' +\n",
    "    sorted_df.loc[missing_dates_mask, 'Mese'].astype(str) + '-01'\n",
    ")\n",
    "\n",
    "# Verify that no 'Data Documento Precedente' values are missing\n",
    "missing_dates_after = sorted_df['Data Documento Precedente'].isna().sum()\n",
    "print(f\"Missing 'Data Documento Precedente' after filling: {missing_dates_after}\")\n",
    "\n",
    "# Forward fill the 'Codice Agente' based on the most recent known value for each 'Ragione Sociale Cliente'\n",
    "sorted_df['Codice Agente'] = sorted_df.groupby('Ragione Sociale Cliente')['Codice Agente'].fillna(method='ffill')\n",
    "\n",
    "# Backward fill in case there are still missing values at the beginning of the groups\n",
    "sorted_df['Codice Agente'] = sorted_df.groupby('Ragione Sociale Cliente')['Codice Agente'].fillna(method='bfill')\n",
    "\n",
    "# Assign temporary Codice Agente for any remaining missing values\n",
    "sorted_df['Codice Agente'].fillna(99, inplace=True)\n",
    "\n",
    "# Verify that no 'Codice Agente' values are missing\n",
    "missing_agente_after = sorted_df['Codice Agente'].isna().sum()\n",
    "print(f\"Missing 'Codice Agente' after filling: {missing_agente_after}\")\n",
    "\n",
    "# Drop unnecessary columns, keep 'Categoria Sconto Vendita'\n",
    "columns_to_keep = [\n",
    "    'Data Documento Precedente', 'Mese', 'Anno', 'Ragione Sociale Cliente', 'Codice Cliente', 'Codice Agente',\n",
    "    'Identificativo Articolo', 'Codice Articolo', 'Marca Articolo', 'Descrizione Articolo', 'Valore', 'Costo', \n",
    "    'Numero Lista', 'Prezzo Articolo', 'Categoria Sconto Vendita'\n",
    "]\n",
    "cleaned_df = sorted_df[columns_to_keep]\n",
    "\n",
    "# Convert numeric columns to appropriate data types\n",
    "cleaned_df['Valore'] = cleaned_df['Valore'].str.replace(',', '.').astype(float)\n",
    "cleaned_df['Costo'] = cleaned_df['Costo'].str.replace(',', '.').astype(float)\n",
    "cleaned_df['Prezzo Articolo'] = cleaned_df['Prezzo Articolo'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# Save the cleaned dataset to a new Excel file\n",
    "cleaned_file_path = \"X:/artor/Downloads/mov_01-01-2024_to_12-06-2024_finalv3.xlsx\"\n",
    "cleaned_df.to_excel(cleaned_file_path, index=False)\n",
    "\n",
    "print(\"Cleaning process completed and saved to\", cleaned_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Shape Comparison': False,\n",
       " 'Column Names Comparison': False,\n",
       " 'First Few Rows Comparison': False}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the cleaned dataset provided by the user\n",
    "cleaned_user_file_path = \"X:/artor/Downloads/movimenti01_2024_06_2024_cleaned.xlsx\"\n",
    "cleaned_user_df = pd.read_excel(cleaned_user_file_path)\n",
    "\n",
    "# Load the cleaned dataset from our process\n",
    "cleaned_our_file_path = 'X:/artor/Downloads/mov_01-01-2024_to_12-06-2024_final.xlsx'\n",
    "cleaned_our_df = pd.read_excel(cleaned_our_file_path)\n",
    "\n",
    "# Compare the two datasets\n",
    "comparison_results = {\n",
    "    'Shape Comparison': cleaned_user_df.shape == cleaned_our_df.shape,\n",
    "    'Column Names Comparison': cleaned_user_df.columns.tolist() == cleaned_our_df.columns.tolist(),\n",
    "    'First Few Rows Comparison': cleaned_user_df.head().equals(cleaned_our_df.head())\n",
    "}\n",
    "\n",
    "comparison_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_23496\\1128323243.py:13: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sorted_df = grouped.apply(lambda x: x.sort_values(by='Data Documento Precedente')).reset_index(drop=True)\n",
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_23496\\1128323243.py:27: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
      "  sorted_df['Codice Agente'] = sorted_df.groupby('Ragione Sociale Cliente')['Codice Agente'].fillna(method='ffill')\n",
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_23496\\1128323243.py:27: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sorted_df['Codice Agente'] = sorted_df.groupby('Ragione Sociale Cliente')['Codice Agente'].fillna(method='ffill')\n",
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_23496\\1128323243.py:30: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
      "  sorted_df['Codice Agente'] = sorted_df.groupby('Ragione Sociale Cliente')['Codice Agente'].fillna(method='bfill')\n",
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_23496\\1128323243.py:30: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sorted_df['Codice Agente'] = sorted_df.groupby('Ragione Sociale Cliente')['Codice Agente'].fillna(method='bfill')\n",
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_23496\\1128323243.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  sorted_df['Codice Agente'].fillna(99, inplace=True)\n",
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_23496\\1128323243.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_df['Valore'] = cleaned_df['Valore'].str.replace(',', '.').astype(float)\n",
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_23496\\1128323243.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_df['Costo'] = cleaned_df['Costo'].str.replace(',', '.').astype(float)\n",
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_23496\\1128323243.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_df['Prezzo Articolo'] = cleaned_df['Prezzo Articolo'].str.replace(',', '.').astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing 'Data Documento Precedente' after filling: 0\n",
      "Missing 'Codice Agente' after filling: 0\n",
      "Cleaning process completed and saved to X:/artor/Downloads/mov_01-01-2024_to_12-06-2024_finalv3.xlsx\n",
      "JSON file saved to X:/artor/Downloads/mov_01-01-2024_to_12-06-2024_final.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the original dataset\n",
    "file_path = \"X:/artor/Downloads/mov_ven_01_06_2024_original.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Sort by 'Numero Lista'\n",
    "df_sorted = df.sort_values(by=['Numero Lista'])\n",
    "\n",
    "# Group by 'Ragione Sociale Cliente' and sort each group by 'Data Documento Precedente'\n",
    "df_sorted['Data Documento Precedente'] = pd.to_datetime(df_sorted['Data Documento Precedente'], format='%Y%m%d', errors='coerce')\n",
    "grouped = df_sorted.groupby(['Ragione Sociale Cliente'])\n",
    "sorted_df = grouped.apply(lambda x: x.sort_values(by='Data Documento Precedente')).reset_index(drop=True)\n",
    "\n",
    "# Fill missing 'Data Documento Precedente' using 'Mese' and 'Anno'\n",
    "missing_dates_mask = sorted_df['Data Documento Precedente'].isna()\n",
    "sorted_df.loc[missing_dates_mask, 'Data Documento Precedente'] = pd.to_datetime(\n",
    "    sorted_df.loc[missing_dates_mask, 'Anno'].astype(str) + '-' +\n",
    "    sorted_df.loc[missing_dates_mask, 'Mese'].astype(str) + '-01'\n",
    ")\n",
    "\n",
    "# Verify that no 'Data Documento Precedente' values are missing\n",
    "missing_dates_after = sorted_df['Data Documento Precedente'].isna().sum()\n",
    "print(f\"Missing 'Data Documento Precedente' after filling: {missing_dates_after}\")\n",
    "\n",
    "# Forward fill the 'Codice Agente' based on the most recent known value for each 'Ragione Sociale Cliente'\n",
    "sorted_df['Codice Agente'] = sorted_df.groupby('Ragione Sociale Cliente')['Codice Agente'].fillna(method='ffill')\n",
    "\n",
    "# Backward fill in case there are still missing values at the beginning of the groups\n",
    "sorted_df['Codice Agente'] = sorted_df.groupby('Ragione Sociale Cliente')['Codice Agente'].fillna(method='bfill')\n",
    "\n",
    "# Assign temporary Codice Agente for any remaining missing values\n",
    "sorted_df['Codice Agente'].fillna(99, inplace=True)\n",
    "\n",
    "# Verify that no 'Codice Agente' values are missing\n",
    "missing_agente_after = sorted_df['Codice Agente'].isna().sum()\n",
    "print(f\"Missing 'Codice Agente' after filling: {missing_agente_after}\")\n",
    "\n",
    "# Drop unnecessary columns, keep 'Categoria Sconto Vendita'\n",
    "columns_to_keep = [\n",
    "    'Data Documento Precedente', 'Mese', 'Anno', 'Ragione Sociale Cliente', 'Codice Cliente', 'Codice Agente',\n",
    "    'Identificativo Articolo', 'Codice Articolo', 'Marca Articolo', 'Descrizione Articolo', 'Valore', 'Costo', \n",
    "    'Numero Lista', 'Prezzo Articolo', 'Categoria Sconto Vendita'\n",
    "]\n",
    "cleaned_df = sorted_df[columns_to_keep]\n",
    "\n",
    "# Convert numeric columns to appropriate data types\n",
    "cleaned_df['Valore'] = cleaned_df['Valore'].str.replace(',', '.').astype(float)\n",
    "cleaned_df['Costo'] = cleaned_df['Costo'].str.replace(',', '.').astype(float)\n",
    "cleaned_df['Prezzo Articolo'] = cleaned_df['Prezzo Articolo'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# Save the cleaned dataset to a new Excel file\n",
    "cleaned_file_path = \"X:/artor/Downloads/mov_01-01-2024_to_12-06-2024_finalv3.xlsx\"\n",
    "cleaned_df.to_excel(cleaned_file_path, index=False)\n",
    "\n",
    "# Convert to JSON format\n",
    "json_file_path = \"X:/artor/Downloads/mov_01-01-2024_to_12-06-2024_final.json\"\n",
    "cleaned_df.to_json(json_file_path, orient='records', date_format='iso')\n",
    "\n",
    "print(\"Cleaning process completed and saved to\", cleaned_file_path)\n",
    "print(\"JSON file saved to\", json_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/artor/Downloads/FILTRATOestrapolo articoli al 26-06-2024 filtrato.xlsx'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = 'C:/Users/artor/Downloads/estrapolo articoli al 26-06-2024 con upa.xlsx'\n",
    "excel_data = pd.ExcelFile(file_path)\n",
    "\n",
    "# Load the specific sheets into DataFrames\n",
    "df_brand_rcs = excel_data.parse('Brand RCS')\n",
    "df_brand_tecdoc = excel_data.parse('Brand TecDoc')\n",
    "df_estrapolo_rcs = excel_data.parse('Estrapolo codici RCS')\n",
    "\n",
    "# Clean up the column names for easier access\n",
    "df_brand_tecdoc.columns = ['Brand ID', 'Brand Name']\n",
    "df_brand_rcs.columns = ['Brand RCS', 'Brand TecDoc', 'ID Brand TecDoc']\n",
    "\n",
    "# Initialize the new columns\n",
    "df_brand_rcs['Brand TecDoc'] = 'NON PRESENTE IN TECDOC'\n",
    "df_brand_rcs['ID Brand TecDoc'] = None\n",
    "\n",
    "# Create a dictionary to map the Brand Name from TecDoc to Brand ID\n",
    "tecdoc_brand_dict = pd.Series(df_brand_tecdoc['Brand ID'].values, index=df_brand_tecdoc['Brand Name']).to_dict()\n",
    "\n",
    "# Function to match the brands and update the dataframe\n",
    "def match_brands(df_brand_rcs):\n",
    "    for i, row in df_brand_rcs.iterrows():\n",
    "        brand_rcs_partial = row['Brand RCS'][:5]\n",
    "        match_found = False\n",
    "        for brand_tecdoc, brand_id in tecdoc_brand_dict.items():\n",
    "            if brand_tecdoc.startswith(brand_rcs_partial):\n",
    "                df_brand_rcs.at[i, 'Brand TecDoc'] = brand_tecdoc\n",
    "                df_brand_rcs.at[i, 'ID Brand TecDoc'] = brand_id\n",
    "                match_found = True\n",
    "                break\n",
    "        if not match_found:\n",
    "            df_brand_rcs.at[i, 'Brand TecDoc'] = 'NON PRESENTE IN TECDOC'\n",
    "            df_brand_rcs.at[i, 'ID Brand TecDoc'] = None\n",
    "\n",
    "# Apply the matching function\n",
    "match_brands(df_brand_rcs)\n",
    "\n",
    "# Create a dictionary for quick lookup from the updated Brand RCS data\n",
    "tecdoc_dict = pd.Series(df_brand_rcs['Brand TecDoc'].values, index=df_brand_rcs['Brand RCS']).to_dict()\n",
    "brand_rcs_dict = pd.Series(df_brand_rcs['ID Brand TecDoc'].values, index=df_brand_rcs['Brand RCS']).to_dict()\n",
    "\n",
    "# Initialize the new columns in the Estrapolo codici RCS sheet\n",
    "df_estrapolo_rcs['Brand TecDoc'] = df_estrapolo_rcs['MARCA']\n",
    "df_estrapolo_rcs['ID Brand TecDoc'] = 'MISSING ID'\n",
    "\n",
    "# Function to update the Estrapolo codici RCS sheet\n",
    "def update_estrapolo_rcs(df_estrapolo_rcs):\n",
    "    for i, row in df_estrapolo_rcs.iterrows():\n",
    "        brand_rcs_partial = row['MARCA'][:5]\n",
    "        if brand_rcs_partial in tecdoc_dict:\n",
    "            tecdoc_brand = tecdoc_dict[brand_rcs_partial]\n",
    "            df_estrapolo_rcs.at[i, 'Brand TecDoc'] = tecdoc_brand\n",
    "            if tecdoc_brand != 'NON PRESENTE IN TECDOC':\n",
    "                df_estrapolo_rcs.at[i, 'ID Brand TecDoc'] = brand_rcs_dict[brand_rcs_partial]\n",
    "            else:\n",
    "                df_estrapolo_rcs.at[i, 'ID Brand TecDoc'] = 'MISSING ID'\n",
    "        else:\n",
    "            df_estrapolo_rcs.at[i, 'Brand TecDoc'] = row['MARCA']\n",
    "            df_estrapolo_rcs.at[i, 'ID Brand TecDoc'] = 'MISSING ID'\n",
    "\n",
    "# Apply the update function\n",
    "update_estrapolo_rcs(df_estrapolo_rcs)\n",
    "\n",
    "# Convert the 'GIACENZA' and 'PRZ. ULT. ACQ.' columns to appropriate numeric types\n",
    "df_estrapolo_rcs['GIACENZA'] = pd.to_numeric(df_estrapolo_rcs['GIACENZA'].str.replace(',', '.'), errors='coerce')\n",
    "df_estrapolo_rcs['PRZ. ULT. ACQ.'] = pd.to_numeric(df_estrapolo_rcs['PRZ. ULT. ACQ.'].str.replace(',', '.'), errors='coerce')\n",
    "# Clean the Estrapolo codici RCS data\n",
    "df_estrapolo_rcs = df_estrapolo_rcs[df_estrapolo_rcs['GIACENZA'] > 0]\n",
    "df_estrapolo_rcs = df_estrapolo_rcs[df_estrapolo_rcs['PRZ. ULT. ACQ.'].notna()]\n",
    "\n",
    "# Reorder the columns\n",
    "df_estrapolo_rcs = df_estrapolo_rcs[['CODICE', 'MARCA', 'Brand TecDoc', 'ID Brand TecDoc', 'DESCRIZIONE', 'GIACENZA', 'PRZ. ULT. ACQ.']]\n",
    "\n",
    "# Save the updated data to a new Excel file\n",
    "updated_file_path = 'C:/Users/artor/Downloads/FILTRATOestrapolo articoli al 26-06-2024 filtrato.xlsx'\n",
    "with pd.ExcelWriter(updated_file_path) as writer:\n",
    "    df_brand_rcs.to_excel(writer, sheet_name='Brand RCS', index=False)\n",
    "    df_brand_tecdoc.to_excel(writer, sheet_name='Brand TecDoc', index=False)\n",
    "    df_estrapolo_rcs.to_excel(writer, sheet_name='Estrapolo codici RCS', index=False)\n",
    "\n",
    "updated_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artor\\AppData\\Local\\Temp\\ipykernel_6436\\2993727428.py:35: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'MISSING ID' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_brand_rcs.loc[df_brand_rcs['Brand RCS'].str.startswith(brand), ['Brand TecDoc', 'ID Brand TecDoc']] = ['NON PRESENTE IN TECDOC', 'MISSING ID']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file saved to C:/Users/artor/Downloads/FILTRATOestrapolo articoli al 26-06-2024 filtrato.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = 'C:/Users/artor/Downloads/estrapolo articoli al 26-06-2024 con upa.xlsx'\n",
    "excel_data = pd.ExcelFile(file_path)\n",
    "\n",
    "# Load the specific sheets into DataFrames\n",
    "df_brand_rcs = excel_data.parse('Brand RCS')\n",
    "df_brand_tecdoc = excel_data.parse('Brand TecDoc')\n",
    "df_estrapolo_rcs = excel_data.parse('Estrapolo codici RCS')\n",
    "\n",
    "# Clean up the column names for easier access\n",
    "df_brand_tecdoc.columns = ['Brand ID', 'Brand Name']\n",
    "df_brand_rcs.columns = ['Brand RCS', 'Brand TecDoc', 'ID Brand TecDoc']\n",
    "\n",
    "# Rename MITSUBOSHI to MITSUBISHI in Brand TecDoc\n",
    "df_brand_tecdoc['Brand Name'] = df_brand_tecdoc['Brand Name'].replace({'MITSUBOSHI': 'MITSUBISHI'})\n",
    "\n",
    "# Rename specified brands in Brand RCS\n",
    "brand_replacements = {\n",
    "    'MERC': 'MERCEDES',\n",
    "    'NISSA': 'NISSAN',\n",
    "    'PEUGE': 'PEUGEOUT',\n",
    "    'PIAGG': 'PIAGGIO',\n",
    "    'RENAU': 'RENAULT',\n",
    "    'SCANI': 'SCANIA',\n",
    "    'TOYOT': 'TOYOTA',\n",
    "    'VW': 'VOLKSWAGEN'\n",
    "}\n",
    "df_brand_rcs['Brand RCS'] = df_brand_rcs['Brand RCS'].replace(brand_replacements)\n",
    "\n",
    "# Force certain brands to be 'NON PRESENTE IN TECDOC'\n",
    "force_non_presente = ['CONTI', 'FRA', 'LEMA', 'MAX', 'MIRA', 'NOVOC', 'STAR', 'TEKNO', 'TURBO']\n",
    "for brand in force_non_presente:\n",
    "    df_brand_rcs.loc[df_brand_rcs['Brand RCS'].str.startswith(brand), ['Brand TecDoc', 'ID Brand TecDoc']] = ['NON PRESENTE IN TECDOC', 'MISSING ID']\n",
    "\n",
    "# Handle METAL and MOTO conflicts\n",
    "df_brand_rcs.loc[df_brand_rcs['Brand RCS'].str.startswith('METAL'), 'Brand RCS'] = 'METALCAUCHO'\n",
    "df_brand_rcs.loc[df_brand_rcs['Brand RCS'].str.startswith('MOTO'), 'Brand RCS'] = 'MOTORCRAFT'\n",
    "\n",
    "# Initialize the new columns\n",
    "df_brand_rcs['Brand TecDoc'] = 'NON PRESENTE IN TECDOC'\n",
    "df_brand_rcs['ID Brand TecDoc'] = None\n",
    "\n",
    "# Create a dictionary to map the Brand Name from TecDoc to Brand ID\n",
    "tecdoc_brand_dict = pd.Series(df_brand_tecdoc['Brand ID'].values, index=df_brand_tecdoc['Brand Name']).to_dict()\n",
    "\n",
    "# Function to match the brands and update the dataframe\n",
    "def match_brands(df_brand_rcs):\n",
    "    for i, row in df_brand_rcs.iterrows():\n",
    "        brand_rcs_partial = row['Brand RCS'][:5]\n",
    "        match_found = False\n",
    "        for brand_tecdoc, brand_id in tecdoc_brand_dict.items():\n",
    "            if brand_tecdoc.startswith(brand_rcs_partial):\n",
    "                df_brand_rcs.at[i, 'Brand TecDoc'] = brand_tecdoc\n",
    "                df_brand_rcs.at[i, 'ID Brand TecDoc'] = brand_id\n",
    "                match_found = True\n",
    "                break\n",
    "        if not match_found:\n",
    "            df_brand_rcs.at[i, 'Brand TecDoc'] = 'NON PRESENTE IN TECDOC'\n",
    "            df_brand_rcs.at[i, 'ID Brand TecDoc'] = None\n",
    "\n",
    "# Apply the matching function\n",
    "match_brands(df_brand_rcs)\n",
    "\n",
    "# Create a dictionary for quick lookup from the updated Brand RCS data\n",
    "tecdoc_dict = pd.Series(df_brand_rcs['Brand TecDoc'].values, index=df_brand_rcs['Brand RCS']).to_dict()\n",
    "brand_rcs_dict = pd.Series(df_brand_rcs['ID Brand TecDoc'].values, index=df_brand_rcs['Brand RCS']).to_dict()\n",
    "\n",
    "# Function to update the Estrapolo codici RCS sheet\n",
    "def update_estrapolo_rcs(df_estrapolo_rcs):\n",
    "    for i, row in df_estrapolo_rcs.iterrows():\n",
    "        brand_rcs_partial = row['MARCA'][:5]\n",
    "        if brand_rcs_partial in tecdoc_dict:\n",
    "            tecdoc_brand = tecdoc_dict[brand_rcs_partial]\n",
    "            if tecdoc_brand != 'NON PRESENTE IN TECDOC':\n",
    "                df_estrapolo_rcs.at[i, 'MARCA'] = tecdoc_brand\n",
    "                df_estrapolo_rcs.at[i, 'ID Brand TecDoc'] = brand_rcs_dict[brand_rcs_partial]\n",
    "            else:\n",
    "                df_estrapolo_rcs.at[i, 'ID Brand TecDoc'] = 'MISSING ID'\n",
    "        else:\n",
    "            df_estrapolo_rcs.at[i, 'ID Brand TecDoc'] = 'MISSING ID'\n",
    "\n",
    "# Apply the update function\n",
    "update_estrapolo_rcs(df_estrapolo_rcs)\n",
    "\n",
    "# Convert the 'GIACENZA' and 'PRZ. ULT. ACQ.' columns to appropriate numeric types\n",
    "df_estrapolo_rcs['GIACENZA'] = pd.to_numeric(df_estrapolo_rcs['GIACENZA'].str.replace(',', '.'), errors='coerce')\n",
    "df_estrapolo_rcs['PRZ. ULT. ACQ.'] = pd.to_numeric(df_estrapolo_rcs['PRZ. ULT. ACQ.'].str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "# Clean the Estrapolo codici RCS data\n",
    "df_estrapolo_rcs = df_estrapolo_rcs[df_estrapolo_rcs['GIACENZA'] > 0]\n",
    "df_estrapolo_rcs = df_estrapolo_rcs[df_estrapolo_rcs['PRZ. ULT. ACQ.'].notna()]\n",
    "\n",
    "# Rename columns and add empty columns\n",
    "df_estrapolo_rcs.rename(columns={\n",
    "    'CODICE': 'ID',\n",
    "    'MARCA': 'BRAND',\n",
    "    'GIACENZA': 'QUANTITÀ'\n",
    "}, inplace=True)\n",
    "df_estrapolo_rcs['PREZZO ITALIA'] = ''\n",
    "df_estrapolo_rcs['PREZZO GERMANIA'] = ''\n",
    "df_estrapolo_rcs['BRAND TYPE'] = df_estrapolo_rcs['BRAND'].apply(lambda x: 'ORIGINAL' if x in [\n",
    "    'FIAT', 'IVECO', 'MAN', 'RENAULT', 'ASTRA', 'AUDI', 'BPW', 'DAF', 'FORD',\n",
    "    'ISUZU', 'JEEP', 'MERCEDES', 'MITSUBISHI', 'NISSAN', 'PEUGEOUT', 'PIAGGIO',\n",
    "    'PSA', 'SAF', 'SCANIA', 'TOYOTA', 'VOLVO', 'VOLKSWAGEN'\n",
    "] else 'AFTERMARKET')\n",
    "\n",
    "# Reorder the columns\n",
    "df_estrapolo_rcs = df_estrapolo_rcs[['ID', 'BRAND', 'ID Brand TecDoc', 'DESCRIZIONE', 'QUANTITÀ', 'PRZ. ULT. ACQ.', 'PREZZO ITALIA', 'PREZZO GERMANIA', 'BRAND TYPE']]\n",
    "\n",
    "# Save the updated data to a new Excel file\n",
    "updated_file_path = 'C:/Users/artor/Downloads/FILTRATOestrapolo articoli al 26-06-2024 filtrato.xlsx'\n",
    "with pd.ExcelWriter(updated_file_path) as writer:\n",
    "    df_brand_rcs.to_excel(writer, sheet_name='Brand RCS', index=False)\n",
    "    df_brand_tecdoc.to_excel(writer, sheet_name='Brand TecDoc', index=False)\n",
    "    df_estrapolo_rcs.to_excel(writer, sheet_name='Estrapolo codici RCS', index=False)\n",
    "\n",
    "print(f\"Updated file saved to {updated_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/artor/Downloads/FILTRATOestrapolo articoli al 26-06-2024 filtrato.xlsx'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = 'C:/Users/artor/Downloads/estrapolo articoli al 26-06-2024 con upa.xlsx'\n",
    "excel_data = pd.ExcelFile(file_path)\n",
    "\n",
    "# Load the specific sheets into DataFrames\n",
    "df_brand_rcs = excel_data.parse('Brand RCS')\n",
    "df_brand_tecdoc = excel_data.parse('Brand TecDoc')\n",
    "df_estrapolo_rcs = excel_data.parse('Estrapolo codici RCS')\n",
    "\n",
    "# Clean up the column names for easier access\n",
    "df_brand_tecdoc.columns = ['Brand ID', 'Brand Name']\n",
    "df_brand_rcs.columns = ['Brand RCS', 'Brand TecDoc', 'ID Brand TecDoc']\n",
    "\n",
    "# Brands to ignore during matching\n",
    "brands_to_ignore = ['CONTI', 'FRA', 'LEMA', 'MAX', 'MIRA', 'NOVOC', 'STAR', 'TEKNO', 'TURBO']\n",
    "\n",
    "# Manual mapping for specific brand conflicts\n",
    "manual_mapping = {'METAL': 'METALCAUCHO', 'MOTO': 'MOTORCRAFT'}\n",
    "\n",
    "# Initialize the new columns\n",
    "df_brand_rcs['Brand TecDoc'] = 'NON PRESENTE IN TECDOC'\n",
    "df_brand_rcs['ID Brand TecDoc'] = None\n",
    "\n",
    "# Create a dictionary to map the Brand Name from TecDoc to Brand ID\n",
    "tecdoc_brand_dict = pd.Series(df_brand_tecdoc['Brand ID'].values, index=df_brand_tecdoc['Brand Name']).to_dict()\n",
    "\n",
    "# Function to match the brands and update the dataframe\n",
    "def match_brands(df_brand_rcs):\n",
    "    for i, row in df_brand_rcs.iterrows():\n",
    "        brand_rcs_partial = row['Brand RCS'][:5]\n",
    "        if brand_rcs_partial in brands_to_ignore:\n",
    "            df_brand_rcs.at[i, 'Brand TecDoc'] = 'NON PRESENTE IN TECDOC'\n",
    "            df_brand_rcs.at[i, 'ID Brand TecDoc'] = None\n",
    "        elif brand_rcs_partial in manual_mapping:\n",
    "            tecdoc_brand = manual_mapping[brand_rcs_partial]\n",
    "            df_brand_rcs.at[i, 'Brand TecDoc'] = tecdoc_brand\n",
    "            df_brand_rcs.at[i, 'ID Brand TecDoc'] = tecdoc_brand_dict.get(tecdoc_brand, None)\n",
    "        else:\n",
    "            match_found = False\n",
    "            for brand_tecdoc, brand_id in tecdoc_brand_dict.items():\n",
    "                if brand_tecdoc.startswith(brand_rcs_partial):\n",
    "                    df_brand_rcs.at[i, 'Brand TecDoc'] = brand_tecdoc\n",
    "                    df_brand_rcs.at[i, 'ID Brand TecDoc'] = brand_id\n",
    "                    match_found = True\n",
    "                    break\n",
    "            if not match_found:\n",
    "                df_brand_rcs.at[i, 'Brand TecDoc'] = 'NON PRESENTE IN TECDOC'\n",
    "                df_brand_rcs.at[i, 'ID Brand TecDoc'] = None\n",
    "\n",
    "# Apply the matching function\n",
    "match_brands(df_brand_rcs)\n",
    "\n",
    "# Create a dictionary for quick lookup from the updated Brand RCS data\n",
    "tecdoc_dict = pd.Series(df_brand_rcs['Brand TecDoc'].values, index=df_brand_rcs['Brand RCS']).to_dict()\n",
    "brand_rcs_dict = pd.Series(df_brand_rcs['ID Brand TecDoc'].values, index=df_brand_rcs['Brand RCS']).to_dict()\n",
    "\n",
    "# Update the Estrapolo codici RCS sheet\n",
    "def update_estrapolo_rcs(df_estrapolo_rcs):\n",
    "    for i, row in df_estrapolo_rcs.iterrows():\n",
    "        brand_rcs_partial = row['MARCA'][:5]\n",
    "        if brand_rcs_partial in tecdoc_dict:\n",
    "            tecdoc_brand = tecdoc_dict[brand_rcs_partial]\n",
    "            if tecdoc_brand != 'NON PRESENTE IN TECDOC':\n",
    "                df_estrapolo_rcs.at[i, 'MARCA'] = tecdoc_brand\n",
    "                df_estrapolo_rcs.at[i, 'ID Brand TecDoc'] = brand_rcs_dict[brand_rcs_partial]\n",
    "            else:\n",
    "                df_estrapolo_rcs.at[i, 'ID Brand TecDoc'] = 'MISSING ID'\n",
    "        else:\n",
    "            df_estrapolo_rcs.at[i, 'ID Brand TecDoc'] = 'MISSING ID'\n",
    "\n",
    "# Apply the update function\n",
    "update_estrapolo_rcs(df_estrapolo_rcs)\n",
    "\n",
    "# Filter out specific brands\n",
    "df_estrapolo_rcs = df_estrapolo_rcs[~df_estrapolo_rcs['MARCA'].isin(['BEX', 'RESO'])]\n",
    "\n",
    "# Rename specific brands\n",
    "rename_dict = {\n",
    "    'MERC': 'MERCEDES', 'NISSA': 'NISSAN', 'PEUGE': 'PEUGEOUT', 'PIAGG': 'PIAGGIO',\n",
    "    'RENAU': 'RENAULT', 'SCANI': 'SCANIA', 'TOYOT': 'TOYOTA', 'VW': 'VOLKSWAGEN',\n",
    "    'AREXO': 'AREXONS', 'COSIB': 'COSIBO', 'COSPE': 'COSPEL', 'EMMER': 'EMMERRE',\n",
    "    'ERREV': 'ERREVI', 'PARTE': 'PARTEX', 'URANI': 'URANIA', 'MITSUBOSHI': 'MITSUBISHI'\n",
    "}\n",
    "df_estrapolo_rcs['MARCA'] = df_estrapolo_rcs['MARCA'].replace(rename_dict)\n",
    "\n",
    "# Convert the 'GIACENZA' and 'PRZ. ULT. ACQ.' columns to appropriate numeric types\n",
    "df_estrapolo_rcs['GIACENZA'] = pd.to_numeric(df_estrapolo_rcs['GIACENZA'].str.replace(',', '.'), errors='coerce')\n",
    "df_estrapolo_rcs['PRZ. ULT. ACQ.'] = pd.to_numeric(df_estrapolo_rcs['PRZ. ULT. ACQ.'].str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "# Clean the Estrapolo codici RCS data\n",
    "df_estrapolo_rcs = df_estrapolo_rcs[df_estrapolo_rcs['GIACENZA'] > 0]\n",
    "df_estrapolo_rcs = df_estrapolo_rcs[df_estrapolo_rcs['PRZ. ULT. ACQ.'].notna()]\n",
    "\n",
    "# Reorder the columns and add new ones\n",
    "df_estrapolo_rcs.rename(columns={\n",
    "    'CODICE': 'ID',\n",
    "    'MARCA': 'BRAND',\n",
    "    'GIACENZA': 'QUANTITÀ',\n",
    "    'PRZ. ULT. ACQ.': 'PRZ. ULT. ACQ.'\n",
    "}, inplace=True)\n",
    "\n",
    "df_estrapolo_rcs = df_estrapolo_rcs[['ID', 'BRAND', 'ID Brand TecDoc', 'DESCRIZIONE', 'QUANTITÀ', 'PRZ. ULT. ACQ.']]\n",
    "df_estrapolo_rcs['PREZZO ITALIA'] = ''\n",
    "df_estrapolo_rcs['PREZZO GERMANIA'] = ''\n",
    "df_estrapolo_rcs['BRAND TYPE'] = df_estrapolo_rcs['BRAND'].apply(lambda x: 'ORIGINAL' if x in [\n",
    "    'FIAT', 'IVECO', 'MAN', 'RENAULT', 'ASTRA', 'AUDI', 'BPW', 'DAF', 'FORD',\n",
    "    'ISUZU', 'JEEP', 'MERCEDES', 'MITSUBISHI', 'NISSAN', 'PEUGEOUT', 'PIAGGIO',\n",
    "    'PSA', 'SAF', 'SCANIA', 'TOYOTA', 'VOLVO', 'VOLKSWAGEN'\n",
    "] else 'AFTERMARKET')\n",
    "\n",
    "# Save the updated data to a new Excel file\n",
    "updated_file_path = 'C:/Users/artor/Downloads/FILTRATOestrapolo articoli al 26-06-2024 filtrato.xlsx'\n",
    "with pd.ExcelWriter(updated_file_path) as writer:\n",
    "    df_brand_rcs.to_excel(writer, sheet_name='Brand RCS', index=False)\n",
    "    df_brand_tecdoc.to_excel(writer, sheet_name='Brand TecDoc', index=False)\n",
    "    df_estrapolo_rcs.to_excel(writer, sheet_name='Estrapolo codici RCS', index=False)\n",
    "\n",
    "updated_file_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
